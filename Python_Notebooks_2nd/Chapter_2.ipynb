{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Random Graph Models\n",
    "\n",
    "In the first part of this notebook, we provide the code required to generate the Figures in Chapter 2 of the textbook.\n",
    "\n",
    "In the second part, we consider the GitHub machine learning (ml) developers graph that we introduced in Chapter 1, and compare various statistics for this graph with the values we get for the random graphs models introduced in Chapter 2.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We use one new package in this notebook called ```powerlaw``` which can be installed via ```pip install powerlaw```.\n",
    "Details and examples of use can be found here: https://arxiv.org/pdf/1305.0215.pdf.\n",
    "\n",
    "As with the previous notebook, make sure to set the data directory properly in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import powerlaw\n",
    "from scipy.stats import poisson\n",
    "from scipy.optimize import fsolve\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Figures for Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.1: size of the giant component\n",
    "\n",
    "We generate several binomial random graphs with $n$ nodes, where we vary the average node degree (thus, the number of edges). We consider $n=100$ below, and you can try for different $n$. Un-comment the second line to run with $n=10,000$ nodes as in the book (this will be much slower).\n",
    "\n",
    "We plot the theoretical giant component size (black line) and the 90% confidence interval from the empirical data in grey, both as a function of the average degree; we see good agreement and we observe the various phases as described in the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n=10000 ## as in the book\n",
    "\n",
    "gc_avg = []\n",
    "gc_std = []\n",
    "\n",
    "## range of values for average degree and number of repeats for each\n",
    "avg_deg = np.arange(.1,10.1,.1)\n",
    "Repeats = 1000\n",
    "\n",
    "## generate random graphs and gather size of giant component\n",
    "for deg in avg_deg:\n",
    "    x = []\n",
    "    p = deg/(n-1)\n",
    "    for rep in range(Repeats):\n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(g.connected_components().giant().vcount())\n",
    "    ## average and standard deviation for a given average degree\n",
    "    gc_avg.append(np.mean(x)) \n",
    "    gc_std.append(np.std(x))\n",
    "\n",
    "## theoretical values\n",
    "th_val = [np.log(n) for i in np.arange(.1,1.1,.1)] ## small values\n",
    "def fn(x,d):\n",
    "    return x+np.exp(-x*d)-1\n",
    "for i in np.arange(1.1,10.1,.1):\n",
    "    th_val.append(n*fsolve(fn,1,args=(i))[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot empirical results (confidence intervals) and theoretical values\n",
    "plt.fill_between(avg_deg,[x[0]-1.654*x[1] for x in zip(gc_avg,gc_std)],\n",
    "                 [x[0]+1.645*x[1] for x in zip(gc_avg,gc_std)],color='lightgray')\n",
    "plt.plot(avg_deg,th_val, color='black')\n",
    "plt.suptitle('Random graph with '+str(n)+' nodes',fontsize=14)\n",
    "plt.title('Theoretical predictions (black) vs empirical results (grey)',fontsize=12)\n",
    "plt.xlabel('average degree',fontsize=14)\n",
    "plt.ylabel('giant component size',fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.2: probability that the graph is connected\n",
    "\n",
    "This is a similar experiment as above, but this time we look at the probability that the random graph is connected.\n",
    "We vary some constant $c$ introduced in the book such that the edge probability for the binomial graphs is given by $(\\log(n)+c)/n$. Once again we compare theory (black line) and experimental results (in grey) with $n=100$ nodes. Un-comment the second line to run with $n=10,000$ nodes as in the book (this will be much slower).\n",
    "\n",
    "In the cell below, the grey area corresponds to a 90% confidence interval for proportions; for empirical proportion $x$ obtained from sample of size $n$, the formula is given by $x \\pm 1.645 \\sqrt{x(1-x)/n}$.\n",
    "\n",
    "Here also we see good agreement between theory and experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "#n = 10000\n",
    "\n",
    "Repeats = 1000 ## number of repeats for each 'c' value\n",
    "\n",
    "## set lower bound for the range of values for 'c'\n",
    "lo = -int(np.floor(np.log(n)*10))/10\n",
    "if lo<-10:\n",
    "    lo = -10\n",
    "c_range = np.arange(lo,10.1,.1)\n",
    "ic_avg=[]\n",
    "\n",
    "## loop over 'c' values\n",
    "for c in c_range:\n",
    "    x = []\n",
    "    p = (c+np.log(n))/n\n",
    "    for rep in range(Repeats):        \n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(int(g.is_connected()))\n",
    "    ic_avg.append(np.mean(x))\n",
    "\n",
    "## theoretical values\n",
    "th = [np.exp(-np.exp(-c)) for c in c_range]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "plt.fill_between(c_range,[x-1.654*np.sqrt(x*(1-x)/n) for x in ic_avg],\n",
    "                 [x+1.645*np.sqrt(x*(1-x)/n) for x in ic_avg],color='lightgray')\n",
    "plt.plot(c_range,th,color='black')\n",
    "plt.suptitle('Random graph with '+str(n)+' nodes',fontsize=14)\n",
    "plt.title('Theoretical predictions (black) vs empirical results (grey)',fontsize=12)\n",
    "plt.xlabel(r'constant $c$',fontsize=14)\n",
    "plt.ylabel('P(graph is connected)',fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.4: Distribution of shortest path lengths\n",
    "\n",
    "We consider a series of binomial random graphs with expected average degree 5, where we vary the number of nodes from $n=50$ to $n=3,200$.\n",
    "\n",
    "We see that as we double the number of nodes, the average shortest path lengths (in the giant component) increases slowly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_len = []\n",
    "## number of nodes\n",
    "n_range = [64,128,256,512,1024,2048]\n",
    "\n",
    "for n in n_range:\n",
    "    p = 5/(n-1)\n",
    "    ## keep giant component\n",
    "    g = ig.Graph.Erdos_Renyi(n=n, p=p).connected_components().giant()\n",
    "    z = g.distances()\n",
    "    sp_len.append([x for y in z for x in y if x>0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5,8.5,1)\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.suptitle('Shortest path length distribution')\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i,j].hist(sp_len[3*i+j], bins=bins, width=.9, density=True, color='darkgrey')\n",
    "        axs[i,j].set_ylim(0,.48)\n",
    "        axs[i,j].set_xticks([1,3,5,7])\n",
    "        axs[i,j].set_title(str(n_range[3*i+j])+' nodes', fontsize=10)\n",
    "        axs[i,j].set_xlabel('path length')\n",
    "        axs[i,j].set_ylabel('proportion')\n",
    "for ax in fig.get_axes():\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.5 Poisson vs degree distributions\n",
    "\n",
    "We plot the degree distribution for binomial random graphs with expected average degree 10, and $n=500$ nodes (the black dots), and we compare with the corresponding Poisson distribution (dashed line).\n",
    "\n",
    "Try increasing $n$; the dots should get closer to the Poisson distribution.\n",
    "\n",
    "Un-comment line 2 to run with $n=10,000$ as in the book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "#n = 10000 ## as in the book\n",
    "\n",
    "p = 10/(n-1)\n",
    "g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "x = [x[0] for x in sorted(Counter(g.degree()).items())]\n",
    "pmf = [poisson.pmf(k,10) for k in x]\n",
    "frq = [x[1]/n for x in sorted(Counter(g.degree()).items())]\n",
    "plt.plot(x,frq,'o',color='black')\n",
    "plt.plot(x,pmf,':',color='black')\n",
    "plt.xlabel('degree',fontsize=14)\n",
    "plt.ylabel('frequency/pmf',fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.6 --  Power law graphs\n",
    "\n",
    "We generate a random graph with $n=10,000$ nodes following power law degree distribution with exponent $\\gamma=2.5$.\n",
    "We do so using the Chung-Lu models described in section 2.5 of the book; we generate simple graphs (no loops or multiedges) and discard 0-degree nodes.\n",
    "\n",
    "We then fit and plot the degree distribution of the obtained graph using the ```powerlaw``` package, see: https://arxiv.org/pdf/1305.0215.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fast Chung-Lu: generate m distinct edges w.r.t. distribution d, no loops\n",
    "def fast_CL(d, m):\n",
    "    n = len(d)    ## number of nodes\n",
    "    s = np.sum(d) \n",
    "    p = [i/s for i in d] ## we draw nodes w.r.t. degrees\n",
    "    target = m ## number to generate\n",
    "    tples = [] ## list of generated edges\n",
    "    ## generate edges (tuples), drop collisions, until m edges are obtained.\n",
    "    while len(tples) < target:\n",
    "        s = target - len(tples) ## number left to generate\n",
    "        e0 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        e1 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        tples.extend([(min(e0[i],e1[i]),max(e0[i],e1[i])) for i in range(len(e0)) if e0[i]!=e1[i]]) ## ignore loops\n",
    "        tples = list(set(tples)) ## drop collisions\n",
    "    return tples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate graph and fit power law model\n",
    "\n",
    "A few remarks regarding the ```powerlaw``` package:\n",
    "\n",
    "* ```xmin``` corresponds to $\\ell'$ in the book\n",
    "* ```alpha``` corresponds to $\\gamma$ in the book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## power law graph\n",
    "np.random.seed(23) ## for reproducibility\n",
    "gamma = 2.5\n",
    "n = 10000\n",
    "\n",
    "## min and max degrees\n",
    "delta = 1\n",
    "Delta = np.sqrt(n)\n",
    "\n",
    "## generate degrees (details in the book)\n",
    "W = []\n",
    "for i in np.arange(1,n+1):\n",
    "    W.append(delta * (n/(i-1+n/(Delta/delta)**(gamma-1)))**(1/(gamma-1)))\n",
    "#deg = [int(np.round(w)) for w in W] ## to enforce integer weights, not an obligation\n",
    "deg = W\n",
    "\n",
    "## generate graph with Chung-Lu model\n",
    "m = int(np.mean(deg)*n/2)\n",
    "tpl = fast_CL(deg,m)\n",
    "g_pl = ig.Graph.TupleList(tpl)\n",
    "\n",
    "## number of isolated nodes (no edges)\n",
    "iso = n-g_pl.vcount()\n",
    "print('number of isolated nodes:',iso,'\\n')\n",
    "\n",
    "## run powerlaw and compute Kolmogorov-Smirnov statistic (details in the book)\n",
    "deg = g_pl.degree()\n",
    "X = powerlaw.Fit(deg)\n",
    "print('\\n\\nRange of degrees in graph:',min(deg),max(deg))\n",
    "print(\"Value of l':\",X.power_law.xmin)\n",
    "print(\"Corresponding value of gamma:\",X.power_law.alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov statistic vs $\\ell$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot K-S statistics vs 'l'\n",
    "x = X.xmins\n",
    "y = X.Ds\n",
    "plt.plot(x, y, '.')\n",
    "\n",
    "## Plot min value with larger dot\n",
    "x = int(X.power_law.xmin)\n",
    "y = X.Ds[x-1]\n",
    "plt.plot([x],[y],'o')\n",
    "plt.xlabel(r'$\\ell$', fontsize=14)\n",
    "plt.ylabel('Kolmogorov-Smirnov statistic', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.6 - inverse (cumulative) cdf vs degree and fitter power law\n",
    "\n",
    "In the first plot, we look at degrees starting from $\\ell'$.\n",
    "\n",
    "In the second plot, we look at the whole range of degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Figure 2.6 - starting from l' \n",
    "fig1 = X.power_law.plot_ccdf(color='black', linestyle='-');\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color='gray', original_data=False, linestyle=':')\n",
    "fig1.set_xlabel('degree', fontsize=13)\n",
    "fig1.set_ylabel('inverse cdf', fontsize=13);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now starting from 1 - need to translate power law line manually\n",
    "fig1 = X.plot_ccdf(linewidth=2, color='gray', original_data=True, linestyle=':')\n",
    "fig1.set_xlabel('degree', fontsize=13)\n",
    "fig1.set_ylabel('inverse cdf', fontsize=13)\n",
    "\n",
    "## get end points for power law fitted line\n",
    "x = [int(X.power_law.xmin), int(X.data[-1:][0])]     ## x-axis: from l' to max value in data\n",
    "delta_y = X.ccdf(original_data=True)[1][x[0]-1]   ## translation for first point\n",
    "y = [delta_y, X.power_law.ccdf()[-1:][0]*delta_y] ## y-axis values\n",
    "plt.plot(x,y,'-',linewidth=2, color='black')\n",
    "print('power law slope:',(np.log10(y[1])-np.log10(y[0]))/(np.log10(x[1])-np.log10(x[0])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## plot K-S statistics vs. exponent (alpha here, gamma' in the book)\n",
    "plt.plot(X.alphas[:50],X.Ds[:50],'.')\n",
    "\n",
    "## Plot min value with larger dot\n",
    "i = int(X.power_law.xmin)\n",
    "x = X.alphas[i-1]\n",
    "y = X.Ds[i-1]\n",
    "plt.plot([x],[y],'o')\n",
    "plt.xlabel(r'$\\alpha$', fontsize=14)\n",
    "plt.ylabel('Kolmogorov-Smirnov statistic', fontsize=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.7: simple $d$-regular graphs\n",
    "\n",
    "We generate several $d$-regular graphs and count how many are simple graphs.\n",
    "We consider $d=2$ to $d=10$, with $n=100$ nodes. Un-comment the second line to run with $n=10,000$ nodes as in the book.\n",
    "\n",
    "We plot the empirical proportion of simple graphs below (black dots), and we compare with the theoretical values (dashed line). We see good agreement even for small value $n=100$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "\n",
    "Repeats = 100\n",
    "Degs = np.arange(2,11) \n",
    "simple = []\n",
    "\n",
    "## count number of simple graphs\n",
    "for deg in Degs:\n",
    "    x = 0\n",
    "    for rep in range(Repeats):\n",
    "        g = ig.Graph.Degree_Sequence([deg for i in range(n)])\n",
    "        x += int(g.is_simple())\n",
    "    simple.append(x/Repeats)\n",
    "th_simple = [np.exp(-(deg*deg-1)/4) for deg in Degs]\n",
    "\n",
    "## plot empirical and theoretical results\n",
    "plt.plot(Degs, simple, 'o', color='black')\n",
    "plt.plot(Degs, th_simple, ':', color='black')\n",
    "plt.xlabel('degree', fontsize=14)\n",
    "plt.ylabel('P(graph is simple)', fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 -- Experiments with random graphs\n",
    "\n",
    "We use the giant component of the **GitHub machine learning (ml) developers** subgraph that we introduced in Chapter 1. Recall this graph has 7,083 nodes and 19,491 edges. \n",
    "\n",
    "We compute several graphs statistics for this \"base graph\", as reported in the first column of **Table 2.8** from the book.\n",
    "\n",
    "We then generate **random** graphs with the same number of nodes and edges using 4 different models:\n",
    "* binomial or Erdos-Renyi: only average degree is used\n",
    "* Chung-Lu: expected degree distribution\n",
    "* Configuration: exact degree distribution\n",
    "* Configuration with Viger method: connected, simple graph is obtained\n",
    "\n",
    "See **section 2.8** of the book for a more complete discussion of the results, but as a general observation, more complex models (such as the configuration model with Viger method) tend to preserve more characteristics of the reference graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the GitHub edge list as tuples and build undirected graph (as in Chapter 1)\n",
    "df = pd.read_csv(datadir+'GitHubDevelopers/musae_git_edges.csv')\n",
    "GitHubGraph = ig.Graph.TupleList([tuple(x) for x in df.values], directed = False, vertex_name_attr='id')\n",
    "\n",
    "## read node attributes\n",
    "Attr = pd.read_csv(datadir+'GitHubDevelopers/musae_git_target.csv')\n",
    "## build attribute dictionaries\n",
    "Names = dict(zip(Attr.id,Attr.name))\n",
    "ML = dict(zip(Attr.id,Attr.ml_target))\n",
    "## add name attributes to graph\n",
    "GitHubGraph.vs['name'] = [Names[i] for i in GitHubGraph.vs['id']]\n",
    "## add a class: 'ml' or 'web' depending on attribute 'ml_label'\n",
    "labels = ['web','ml']\n",
    "GitHubGraph.vs['class'] = [labels[ML[i]] for i in GitHubGraph.vs['id']]\n",
    "\n",
    "## for github, 9739 are ml developers, build the subgraph and keep the giant component\n",
    "subgraph_ml = GitHubGraph.subgraph([v for v in GitHubGraph.vs() if v['class']=='ml'])\n",
    "subgraph_ml = subgraph_ml.connected_components().giant()\n",
    "print(subgraph_ml.vcount(),'nodes and',subgraph_ml.ecount(),'edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return statistics in Table 2.8 \n",
    "def baseStats(G):\n",
    "    deg = G.degree()\n",
    "    return [G.vcount(),G.ecount(),np.min(deg),np.mean(deg),np.median(deg),np.max(deg),G.diameter(),\n",
    "     np.max(G.connected_components().membership)+1,G.connected_components().giant().vcount(),sum([x==0 for x in G.degree()]),\n",
    "     G.transitivity_undirected(),G.transitivity_avglocal_undirected()]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42) ## for reproducibility with numpy\n",
    "random.seed(42)    ## for reproducibility with igraph\n",
    "\n",
    "## Compute and store statistics for Base (subgraph_ml) graphs\n",
    "S = []\n",
    "S.append(['Base Graph'] + baseStats(subgraph_ml))\n",
    "\n",
    "## Append statistics for Erdos-Renyi graph with same number of nodes and edges\n",
    "g_er = ig.Graph.Erdos_Renyi(n=subgraph_ml.vcount(), m=subgraph_ml.ecount())\n",
    "S.append(['Erdos-Renyi'] + baseStats(g_er))\n",
    "\n",
    "## Append statistics for Chung-Lu graph with same (expected) degree distribution\n",
    "tuples = fast_CL(subgraph_ml.degree(),subgraph_ml.ecount()) \n",
    "g_cl = ig.Graph.Erdos_Renyi(n=subgraph_ml.vcount(), m=0)\n",
    "g_cl.add_edges(tuples)\n",
    "S.append(['Chung-Lu'] + baseStats(g_cl))\n",
    "\n",
    "## Append statistics for configuration model graph with same degree distribution\n",
    "g_cm = ig.Graph.Degree_Sequence(subgraph_ml.degree(), method='simple')\n",
    "S.append(['Configuration'] + baseStats(g_cm))\n",
    "\n",
    "## Append statistics for configuration model simple graph with same degree distribution\n",
    "g_cmvl = ig.Graph.Degree_Sequence(subgraph_ml.degree(), method='vl')\n",
    "S.append(['Configuration (VL)'] + baseStats(g_cmvl))\n",
    "\n",
    "## Store in dataframe and show results\n",
    "df = pd.DataFrame(S,columns=['graph','nodes','edges',r'$\\delta = d_{min}$',r'$d_{mean}$',\n",
    "                             r'$d_{median}$',r'$\\Delta = d_{max}$','diameter','components','largest','isolates',\n",
    "                             r'$C_{glob}$',r'$C_{loc}$']).transpose()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shortest path length distribution\n",
    "\n",
    "We compute and compare the shortest path length distribution for several node pairs and for the 5 graphs we have (GitHub ml reference graph, and 4 random graphs). Sampling is used to speed-up the process.\n",
    "\n",
    "We consider the giant component for disconnected graphs.\n",
    "\n",
    "We see a reasonably high similarity for all graphs, with the binomial random graph having slightly longer path lengths due to the absence of high degree (hub) nodes in that model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sampling -- doing all vertices is slower\n",
    "sample_size = 1000\n",
    "\n",
    "## using the giant component for disconnected graphs\n",
    "g_er_gcc = g_er.connected_components().giant()\n",
    "g_cl_gcc = g_cl.connected_components().giant()\n",
    "g_cm_gcc = g_cm.connected_components().giant()\n",
    "\n",
    "## compute shortest paths (exclude 0-length, i.e. distance to self)\n",
    "## n.b.: we sample separately since we use the giant components and graphs may\n",
    "##       have a different number of nodes (except the first and last one)\n",
    "sp_sg = []\n",
    "for v in np.random.choice(subgraph_ml.vcount(),size=sample_size,replace=False):\n",
    "    sp_sg.extend([i for i in subgraph_ml.distances(source=v)[0] if i>0])\n",
    "sp_er = []\n",
    "for v in np.random.choice(g_er_gcc.vcount(),size=sample_size,replace=False):\n",
    "    sp_er.extend([i for i in g_er_gcc.distances(source=v)[0] if i>0])\n",
    "sp_cl = []\n",
    "for v in np.random.choice(g_cl_gcc.vcount(),size=sample_size,replace=False):\n",
    "    sp_cl.extend([i for i in g_cl_gcc.distances(source=v)[0] if i>0])\n",
    "sp_cm = []\n",
    "for v in np.random.choice(g_cm_gcc.vcount(),size=sample_size,replace=False):\n",
    "    sp_cm.extend([i for i in g_cm_gcc.distances(source=v)[0] if i>0])\n",
    "sp_cmvl = []\n",
    "for v in np.random.choice(g_cmvl.vcount(),size=sample_size,replace=False):\n",
    "    sp_cmvl.extend([i for i in g_cmvl.distances(source=v)[0] if i>0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## compare shortest path length diostributions\n",
    "bins = np.arange(0.5,11.5,1)\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "fig.suptitle('Shortest path length distribution')\n",
    "\n",
    "## plot the 5 histograms\n",
    "axs[0,0].hist(sp_sg, bins=bins, width=.9, density=True, color='darkgrey')\n",
    "axs[0,0].set_title('GitHub (ml)',fontsize=10)\n",
    "axs[0,1].hist(sp_er, bins=bins, width=.9, density=True, color='darkgrey')\n",
    "axs[0,1].set_title('Erdos-Renyi',fontsize=10)\n",
    "axs[0,2].hist(sp_cl, bins=bins, width=.9, density=True, color='darkgrey')\n",
    "axs[0,2].set_title('Chung-Lu',fontsize=10)\n",
    "axs[1,0].hist(sp_cm, bins=bins, width=.9, density=True, color='darkgrey')\n",
    "axs[1,0].set_title('Configuration',fontsize=10)\n",
    "axs[1,1].hist(sp_cmvl, bins=bins, width=.9, density=True, color='darkgrey')\n",
    "axs[1,1].set_title('Configuration (VL)',fontsize=10)\n",
    "\n",
    "## set uniform y-range and ticks\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        axs[i,j].set_ylim(0,.5)\n",
    "        axs[i,j].set_xticks([2,4,6,8,10])\n",
    "\n",
    "## adjust 3-2 format\n",
    "axs[1,2].set_visible(False)\n",
    "axs[1,0].set_position([0.24,0.08,0.228,0.343])\n",
    "axs[1,1].set_position([0.55,0.08,0.228,0.343])\n",
    "\n",
    "## labels only on the outer axis\n",
    "axs[0,0].set_ylabel('proportion')  \n",
    "axs[1,0].set_ylabel('proportion')  \n",
    "axs[1,0].set_xlabel('path length')  \n",
    "axs[1,1].set_xlabel('path length')  \n",
    "axs[0,1].get_yaxis().set_ticklabels([])\n",
    "axs[0,2].get_yaxis().set_ticklabels([]);\n",
    "\n",
    "## add mean values\n",
    "axs[0,0].text(6,.43,'mean: '+str(float('%.3g' % np.mean(sp_sg))),fontsize=8)\n",
    "axs[0,1].text(6,.43,'mean: '+str(float('%.3g' % np.mean(sp_er))),fontsize=8)\n",
    "axs[0,2].text(6,.43,'mean: '+str(float('%.3g' % np.mean(sp_cl))),fontsize=8)\n",
    "axs[1,0].text(6,.43,'mean: '+str(float('%.3g' % np.mean(sp_cm))),fontsize=8)\n",
    "axs[1,1].text(6,.43,'mean: '+str(float('%.3g' % np.mean(sp_cmvl))),fontsize=8);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More power law tests - GitHub subgraphs and Grid graph\n",
    "\n",
    "We try to fit power law for the degree distributions as we did before, this time for 3 real graphs:\n",
    "* GitHub ml developers (giant component)\n",
    "* GitHub web developers (giant component)\n",
    "* Grid (Europe power grid graph, giant component)\n",
    "\n",
    "While the first two exhibit power law degree distribution, this is not the case for the Grid graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub ml subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the subgraphs\n",
    "subgraph_ml = GitHubGraph.subgraph([v for v in GitHubGraph.vs() if v['class']=='ml'])\n",
    "subgraph_ml =subgraph_ml.connected_components().giant()\n",
    "\n",
    "## estimates for l' (xmin) and gamma (alpha)\n",
    "deg = subgraph_ml.degree()\n",
    "X = powerlaw.Fit(deg)\n",
    "print('\\ngamma:',X.power_law.alpha)\n",
    "print('l\\':',X.power_law.xmin)\n",
    "print('KS statistic:',X.power_law.D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting from l' \n",
    "fig1 = X.power_law.plot_ccdf(color='black', linestyle='-');\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color='gray', original_data=False, linestyle=':')\n",
    "fig1.set_xlabel('degree', fontsize=13)\n",
    "fig1.set_ylabel('inverse cdf', fontsize=13);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub web subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subgraph_web = GitHubGraph.subgraph([v for v in GitHubGraph.vs() if v['class']=='web'])\n",
    "subgraph_web =subgraph_web.connected_components().giant()\n",
    "\n",
    "## estimates for l' (xmin) and gamma (alpha)\n",
    "deg = subgraph_web.degree()\n",
    "X = powerlaw.Fit(deg)\n",
    "print('\\ngamma:',X.power_law.alpha)\n",
    "print('l\\':',X.power_law.xmin)\n",
    "print('KS statistic:',X.power_law.D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting from l' \n",
    "fig1 = X.power_law.plot_ccdf(color='black', linestyle='-');\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color='gray', original_data=False, linestyle=':')\n",
    "fig1.set_xlabel('degree', fontsize=13)\n",
    "fig1.set_ylabel('inverse cdf', fontsize=13);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = ig.Graph.Read_Ncol(datadir+'GridEurope/gridkit_europe-highvoltage.edges', directed=False)\n",
    "Grid = Grid.simplify()\n",
    "## keep the giant component\n",
    "Grid = Grid.connected_components().giant()\n",
    "\n",
    "## estimates for l' (xmin) and gamma (alpha)\n",
    "deg = Grid.degree()\n",
    "X = powerlaw.Fit(deg)\n",
    "print('\\ngamma:',X.power_law.alpha)\n",
    "print('l\\':',X.power_law.xmin)\n",
    "print('KS statistic:',X.power_law.D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting from l' \n",
    "fig1 = X.power_law.plot_ccdf(color='black', linestyle='-');\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color='gray', original_data=False, linestyle=':')\n",
    "fig1.set_xlabel('degree', fontsize=13)\n",
    "fig1.set_ylabel('inverse cdf', fontsize=13);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent sets\n",
    "\n",
    "Illustrating a few functions to find independent sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random graph with (at least one) independent set \n",
    "## n: nodes, s: independent set size, d: avg degree\n",
    "def indepSet(n, s, d):\n",
    "    N = n-s\n",
    "    di = n*d//2-s*d\n",
    "    ## random graph with N nodes\n",
    "    g = ig.Graph.Erdos_Renyi(n=N,m=di)\n",
    "    ## extra nodes\n",
    "    g.add_vertices(s)\n",
    "    ## assign remaining degree to extra nodes\n",
    "    z = np.random.choice(np.arange(N,n),size=s*d)\n",
    "    deg = [x[1] for x in sorted(Counter(z).items())]\n",
    "    for i in range(len(deg)):\n",
    "        e = np.random.choice(N,deg[i],replace=False)\n",
    "        for j in e:\n",
    "            g.add_edge(j,i+N)\n",
    "    p = list(np.random.permutation(n))\n",
    "    G = g.permute_vertices(p)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 50 nodes, set size 10, average degree 20\n",
    "g = indepSet(50, 10, 20)\n",
    "\n",
    "## every set of size min or more\n",
    "#ivs = g.independent_vertex_sets(min=9)\n",
    "\n",
    "## largest set(s) only\n",
    "ivs = g.largest_independent_vertex_sets()\n",
    "\n",
    "## maximal sets (that can't be extended)\n",
    "#ivs = g.maximal_independent_vertex_sets()\n",
    "\n",
    "print(g.independence_number())\n",
    "\n",
    "ivs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexnetworks",
   "language": "python",
   "name": "complexnetworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
