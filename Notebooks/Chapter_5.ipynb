{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* pip: python-igraph, partition-igraph and umap-learn\n",
    "* set the directories in the next cell\n",
    "\n",
    "### Installing Julia and ABCD\n",
    "\n",
    "We use the command line interface option to run ABCD below. \n",
    "The following steps are required:\n",
    "\n",
    "* install Julia (we used version 1.4.2) from https://julialang.org/downloads/\n",
    "* download ABCD from https://github.com/bkamins/ABCDGraphGenerator.jl\n",
    "* adjust the 'abcd_path' in the next cell to the location of the 'utils' subdirectory of ABCD\n",
    "* run 'julia abcd_path/install.jl' to install the required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set those accordingly\n",
    "datadir = '../Datasets/'\n",
    "abcd_path = '~/ABCD/utils/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import os\n",
    "import umap\n",
    "import pickle\n",
    "import partition_igraph\n",
    "import subprocess\n",
    "from sklearn.metrics import adjusted_mutual_info_score as AMI\n",
    "\n",
    "## we use those for the book, but you can change for other colors\n",
    "cls_edges = 'gainsboro'\n",
    "cls = ['silver','dimgray','black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To produce LaTeX from a DataFrame\n",
    "#df = df.round(decimals=3)\n",
    "#print(df.to_latex(index=False))\n",
    "#print(df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zachary (karate) graph\n",
    "\n",
    "A small graph with 34 nodes and two \"ground-truth\" communities;\n",
    "modularity-based algorithms will typically find 5 communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ig.Graph.Famous('zachary')\n",
    "z.vs['size'] = 10\n",
    "z.vs['name'] = [str(i) for i in range(z.vcount())]\n",
    "z.vs['label'] = [str(i) for i in range(z.vcount())]\n",
    "z.vs['label_size'] = 8\n",
    "z.es['color'] = cls_edges\n",
    "z.vs['comm'] = [0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "z.vs['color'] = [cls[i] for i in z.vs['comm']]\n",
    "#ig.plot(z, 'zachary_gt.eps', bbox=(0,0,300,200))\n",
    "ig.plot(z, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the communities w.r.t. strong/weak definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## strong criterion: internal degree is larger for each node\n",
    "## only two nodes do not qualify\n",
    "for i in range(z.vcount()):\n",
    "    c = z.vs[i]['comm']\n",
    "    n = [z.vs[v]['comm']==c for v in z.neighbors(i)]\n",
    "    if sum(n)<=len(n)-sum(n):\n",
    "        print('node',i,'has internal degree',sum(n),'external',len(n)-sum(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weak criterion: total internal degree > total external degree\n",
    "## both communities satisfy this criterion\n",
    "I = [0,0]\n",
    "E = [0,0]\n",
    "for i in range(z.vcount()):\n",
    "    c = z.vs[i]['comm']\n",
    "    n = [z.vs[v]['comm']==c for v in z.neighbors(i)]\n",
    "    I[c] += sum(n)\n",
    "    E[c] += len(n)-sum(n)\n",
    "print('community 0 internal degree',I[0],'external',E[0])\n",
    "print('community 1 internal degree',I[1],'external',E[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering and dendrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Girvan-Newman algorithm\n",
    "gn = z.community_edge_betweenness()\n",
    "#ig.plot(gn,'zachary_dendrogram.eps',bbox=(0,0,300,300))\n",
    "ig.plot(gn,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute modularity at each possible cut\n",
    "q = []\n",
    "for i in np.arange(z.vcount()):\n",
    "    q.append(z.modularity(gn.as_clustering(n=i+1)))\n",
    "plt.plot(np.arange(1,1+z.vcount()),q,'o-',color='black')\n",
    "plt.xlabel('number of clusters',fontsize=14)\n",
    "plt.ylabel('modularity',fontsize=14);\n",
    "#plt.savefig('zachary_modularity.eps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show result with 2 clusters -- only 1 node is misclassified\n",
    "z.vs['gn'] = gn.as_clustering(n=2).membership\n",
    "print('AMI:',AMI(z.vs['comm'],z.vs['gn']))\n",
    "print('q:',z.modularity(z.vs['gn']))\n",
    "\n",
    "z.vs['size'] = 10\n",
    "z.vs['name'] = [str(i) for i in range(z.vcount())]\n",
    "z.vs['label'] = [str(i) for i in range(z.vcount())]\n",
    "z.vs['label_size'] = 8\n",
    "z.es['color'] = cls_edges\n",
    "z.vs['comm'] = [0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "#z.vs['color'] = [cls[i] for i in z.vs['comm']]\n",
    "z.vs['color'] = [cls[i] for i in z.vs['gn']]\n",
    "#ig.plot(z, 'zachary_2.eps',bbox=(0,0,300,200))\n",
    "ig.plot(z,bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show result with optimal modularity (5 clusters)\n",
    "z.vs['label'] = gn.as_clustering(n=5).membership\n",
    "print('AMI:',AMI(z.vs['comm'],z.vs['label']))\n",
    "print('q:',z.modularity(z.vs['label']))\n",
    "z.vs['color'] = [cls[i] for i in z.vs['comm']]\n",
    "z.vs['size'] = 10\n",
    "z.vs['label_size'] = 8\n",
    "#ig.plot(z, 'zachary_5.eps',bbox=(0,0,300,200))\n",
    "ig.plot(z,bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD graph with 100 nodes\n",
    "\n",
    "This graph has 3 communities; with hierarchical clustering, we compare modularity and AMI for each possible cut.\n",
    "\n",
    "Parameters: gamma=3, tau=2, degree range [5,15], comm size range [25,50], xi=.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "g = ig.Graph.Read_Ncol(datadir+'ABCD/abcd_100.dat',directed=False)\n",
    "c = np.loadtxt(datadir+'ABCD/abcd_100_comms.dat',dtype='uint16',usecols=(1))\n",
    "g.vs['comm'] = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "gt = {k:(v-1) for k,v in enumerate(g.vs['comm'])}\n",
    "## map between int(name) to key\n",
    "n2k = {int(v):k for k,v in enumerate(g.vs['name'])}\n",
    "g.vs['size'] = 7\n",
    "g.es['color'] = cls_edges\n",
    "g.vs['color'] = [cls[i] for i in g.vs['comm']]\n",
    "ig.plot(g, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman algorithm -- modularity and AMI for each cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "a = []\n",
    "gn = g.community_edge_betweenness()\n",
    "for i in np.arange(g.vcount()):\n",
    "    q.append(g.modularity(gn.as_clustering(n=i+1)))\n",
    "    a.append(AMI(g.vs['comm'],gn.as_clustering(n=i+1).membership))\n",
    "plt.plot(np.arange(1,1+g.vcount()),q,'.-',color='black',label='modularity')\n",
    "plt.plot(np.arange(1,1+g.vcount()),a,'.-',color='grey',label='AMI')\n",
    "plt.xlabel('number of clusters',fontsize=14)\n",
    "plt.ylabel('modularity or AMI',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('abcd_dendrogram.eps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.DataFrame(np.array([q,a]).transpose(),columns=['q','AMI'])\n",
    "df = D.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## To produce LaTeX from a DataFrame\n",
    "df = df.round(decimals=3)\n",
    "print(df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AMI\n",
    "g.vs['gn'] = gn.as_clustering(n=3).membership\n",
    "print('AMI:',AMI(g.vs['comm'],g.vs['gn']))\n",
    "print('q:',g.modularity(g.vs['gn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what would we get with 4 clusters?\n",
    "## we see a few nodes get splitted from one community\n",
    "g.vs['gn'] = gn.as_clustering(n=4).membership\n",
    "cls = ['silver','dimgray','black','white']\n",
    "g.vs['color'] = [cls[i] for i in g.vs['gn']]\n",
    "#ig.plot(g, 'abcd_4.eps', bbox=(0,0,300,200))\n",
    "ig.plot(g, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## those form a triangle\n",
    "sg = g.subgraph([v for v in g.vs() if v['gn']==3])\n",
    "ig.plot(sg, bbox=(0,0,100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD with varying xi\n",
    "\n",
    "Here we show a typical way to compare graph clustering using benchmark graphs. \n",
    "\n",
    "We pick some model, here ABCD, and we vary the noise parameter (0 <= xi <= 1). \n",
    "\n",
    "With ABCD, the larger xi is, the closer we are to a random Chung-Lu or configuration model graph (i.e. where only the degree distribution matters). \n",
    "\n",
    "For xi=0, we get pure communities (all edges are internal).\n",
    "\n",
    "The code below can take a while to run; a pickle file with results is included in the Data directory;\n",
    "\n",
    "To re-run from scratch, uncomment the cell below.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## This can take a while in view of the number of runs, mainly due to the clustering algorithms\n",
    "## You can reduce the number of repeats (REP) for a faster test\n",
    "\n",
    "L = []   ## store results in a list\n",
    "REP = 30  ## number of graphs for each value of xi\n",
    "XIs = [x/100 for x in np.arange(10,81,5)] ## values for xi\n",
    "\n",
    "for rep in range(REP):\n",
    "    print('repeat number',rep)\n",
    "    ## generate new degree and community size values\n",
    "    cmd = 'julia '+abcd_path+'deg_sampler.jl deg.dat 2.5 10 50 1000 1000'\n",
    "    os.system(cmd)\n",
    "    cmd = 'julia '+abcd_path+'com_sampler.jl cs.dat 1.5 50 100 1000 1000'\n",
    "    os.system(cmd)\n",
    "    ## generate graphs for a range of xi \n",
    "    for xi in XIs:\n",
    "        cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "                +str(xi)+' false false'\n",
    "        os.system(cmd)\n",
    "        ## compute AMI for various clustering algorithms\n",
    "        g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "        c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "        g.vs['comm'] = [c[int(x['name'])-1] for x in g.vs]\n",
    "        ## clustering\n",
    "        L.append(['ECG',xi,AMI(g.community_ecg().membership,g.vs['comm'])])\n",
    "        L.append(['Louvain',xi,AMI(g.community_multilevel().membership,g.vs['comm'])])\n",
    "        L.append(['Infomap',xi,AMI(g.community_infomap().membership,g.vs['comm'])])\n",
    "        L.append(['Label Prop.',xi,AMI(g.community_label_propagation().membership,g.vs['comm'])])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results (list L)\n",
    "#pickle.dump(L, open( datadir+\"ABCD/abcd_study.pkl\", \"wb\" ) )\n",
    "\n",
    "## load L and train/val/test ids\n",
    "L = pickle.load(open(datadir+\"ABCD/abcd_study.pkl\",\"rb\"))\n",
    "\n",
    "## save in dataframe and take averages\n",
    "D = pd.DataFrame(L,columns=['algo','xi','AMI'])\n",
    "X = D.groupby(by=['algo','xi']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = ['ECG','Louvain','Infomap','Label Prop.']\n",
    "lt = ['-','--',':','-.','--',':']\n",
    "cl = ['blue','green','purple','red','red','blue']\n",
    "for i in range(len(a)):\n",
    "    #plt.plot(X.loc[(a[i])].index,X.loc[(a[i])],lt[i],label=a[i],color=cl[i])\n",
    "    plt.plot(X.loc[(a[i])].index,X.loc[(a[i])],lt[i],label=a[i],color='black')\n",
    "plt.xlabel(r'ABCD noise ($\\xi$)',fontsize=14)\n",
    "plt.ylabel('AMI',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('abcd_study.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Look at standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = D.groupby(by=['algo','xi']).std()\n",
    "a = ['ECG','Louvain','Infomap','Label Prop.']\n",
    "#a = ['ECG','Louvain','Infomap','Label Prop.','Leiden','CNM']\n",
    "lt = ['-','--',':','-.','--',':']\n",
    "cl = ['blue','green','purple','red','red','blue']\n",
    "for i in range(len(a)):\n",
    "    #plt.plot(S.loc[(a[i])].index,S.loc[(a[i])],lt[i],label=a[i],color=cl[i])\n",
    "    plt.plot(S.loc[(a[i])].index,S.loc[(a[i])],lt[i],label=a[i],color='black')\n",
    "plt.xlabel(r'ABCD noise ($\\xi$)',fontsize=14)\n",
    "plt.ylabel('Standard Deviation (AMI)',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('abcd_study_stdv.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stability \n",
    "\n",
    "This study is similar to the previous one, but we compare successive partitions for each algorithm instead of comparing with the ground truth.\n",
    "\n",
    "The code below can take a while to run; a pickle file with results is included in the Data directory;\n",
    "\n",
    "To re-run from scratch, uncomment the cell below.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## This can take a while in view of the number of runs\n",
    "## You can reduce the number of repeats (REP) for a faster test\n",
    "\n",
    "Ls = []   ## store results in a list\n",
    "REP = 30  ## number of graphs for each value of xi\n",
    "XIs = [x/100 for x in np.arange(10,81,5)] ## values for xi\n",
    "\n",
    "for rep in range(REP):\n",
    "    print('repeat number',rep)\n",
    "    ## generate new degree and community size values\n",
    "    cmd = 'julia '+abcd_path+'deg_sampler.jl deg.dat 2.5 10 50 1000 1000'\n",
    "    os.system(cmd)\n",
    "    cmd = 'julia '+abcd_path+'com_sampler.jl cs.dat 1.5 50 100 1000 1000'\n",
    "    os.system(cmd)\n",
    "    ## generate graphs for a range of xi \n",
    "    for xi in XIs:\n",
    "        cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "                +str(xi)+' false false'\n",
    "        os.system(cmd)\n",
    "        ## compute AMI running various clustering algorithms twice\n",
    "        g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "        ml1 = g.community_multilevel().membership\n",
    "        ec1 = g.community_ecg().membership\n",
    "        lp1 = g.community_label_propagation().membership\n",
    "        im1 = g.community_infomap().membership\n",
    "        ## permute vertices\n",
    "        idx = np.random.permutation(g.vcount())\n",
    "        gp = ig.Graph.Erdos_Renyi(n=g.vcount(),p=0)\n",
    "        for e in g.es():\n",
    "            gp.add_edge(idx[e.tuple[0]],idx[e.tuple[1]])\n",
    "        ml = gp.community_multilevel().membership\n",
    "        ml2 = [ml[idx[i]] for i in range(len(idx))]\n",
    "        ec = gp.community_ecg().membership\n",
    "        ec2 = [ml[idx[i]] for i in range(len(idx))]\n",
    "        lp = gp.community_label_propagation().membership\n",
    "        lp2 = [lp[idx[i]] for i in range(len(idx))]\n",
    "        im = gp.community_infomap().membership\n",
    "        im2 = [im[idx[i]] for i in range(len(idx))]        \n",
    "        Ls.append(['ECG',xi,AMI(ec1,ec2)])\n",
    "        Ls.append(['Louvain',xi,AMI(ml1,ml2)])\n",
    "        Ls.append(['Label Prop.',xi,AMI(lp1,lp2)])\n",
    "        Ls.append(['Infomap',xi,AMI(im1,im2)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results (list Ls)\n",
    "#pickle.dump(Ls, open( datadir+\"ABCD/abcd_study_stability.pkl\", \"wb\" ) )\n",
    "\n",
    "## load L and train/val/test ids\n",
    "Ls = pickle.load(open(datadir+\"ABCD/abcd_study_stability.pkl\",\"rb\"))\n",
    "\n",
    "## save in dataframe and take averages\n",
    "D = pd.DataFrame(Ls,columns=['algo','xi','AMI'])\n",
    "X = D.groupby(by=['algo','xi']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = ['ECG','Louvain','Leiden','CNM']\n",
    "a = ['ECG','Louvain','Infomap','Label Prop.']\n",
    "lt = ['-','--',':','-.']\n",
    "for i in range(len(a)):\n",
    "    plt.plot(X.loc[(a[i])].index,X.loc[(a[i])],lt[i],label=a[i],color='black')\n",
    "plt.xlabel(r'ABCD noise ($\\xi$)',fontsize=14)\n",
    "plt.ylabel('AMI between successive runs',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('abcd_study_stability.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity, resolution limit and rings of cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n cliques of size s\n",
    "def ringOfCliques(n,s):\n",
    "    roc = ig.Graph.Erdos_Renyi(n=n*s,p=0)\n",
    "    ## cliques\n",
    "    for i in range(n):\n",
    "        for j in np.arange(s*i,s*(i+1)):\n",
    "            for k in np.arange(j+1,s*(i+1)):\n",
    "                roc.add_edge(j,k)\n",
    "    ## ring\n",
    "    for i in range(n):\n",
    "        if i>0:\n",
    "            roc.add_edge(s*i-1,s*i)\n",
    "        else:\n",
    "            roc.add_edge(n*s-1,0)\n",
    "    roc.vs['size'] = 8\n",
    "    roc.vs['color'] = cls[2]\n",
    "    roc.es['color'] = cls_edges\n",
    "    return roc\n",
    "roc = ringOfCliques(10,3)\n",
    "#ig.plot(roc,'ring_3.eps',bbox=(0,0,300,300))     \n",
    "ig.plot(roc,bbox=(0,0,300,300))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare number of cliques and number of clusters found\n",
    "L = []\n",
    "s = 3\n",
    "for n in np.arange(3,50,3):\n",
    "    roc = ringOfCliques(n,s)\n",
    "    ml = np.max(roc.community_multilevel().membership)+1\n",
    "    ec = np.max(roc.community_ecg().membership)+1\n",
    "    cnm = np.max(roc.community_fastgreedy().as_clustering().membership)+1\n",
    "    L.append([n,ml,ec,cnm])\n",
    "D = pd.DataFrame(L,columns=['n','Louvain','ECG','CNM'])\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(D['n'],D['Louvain'],'--o',color='black',label='Louvain')\n",
    "plt.plot(D['n'],D['ECG'],'-o',color='black',label='ECG')\n",
    "plt.plot(D['n'],D['CNM'],':o',color='black',label='CNM')\n",
    "\n",
    "plt.xlabel('number of '+str(s)+'-cliques',fontsize=14)\n",
    "plt.ylabel('number of clusters found',fontsize=14)\n",
    "plt.legend(fontsize=14);\n",
    "#plt.savefig('rings.eps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Louvain communities with 10 3-cliques\n",
    "\n",
    "roc = ringOfCliques(n=10,s=3)\n",
    "roc.vs['ml'] = roc.community_multilevel().membership\n",
    "roc.vs['color'] = [cls[x%3] for x in roc.vs['ml']]\n",
    "#ig.plot(roc,'ring_3_q.eps', bbox=(0,0,300,300))\n",
    "ig.plot(roc,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ECG weights in this case: all 30 clique edges have max score\n",
    "\n",
    "roc.es['W'] = roc.community_ecg().W\n",
    "Counter(roc.es['W'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ego nets and more\n",
    "\n",
    "* we consider the airport graph we already saw\n",
    "* we consider a simple, undirected veersion (no loops, directions or edge weights)\n",
    "* we compare ego-nets (1 and 2-hops subgraphs from a given node) with clusters obtained via graph clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read edges and build simple undirected graph\n",
    "D = pd.read_csv(datadir+'Airports/connections.csv')\n",
    "g = ig.Graph.TupleList([tuple(x) for x in D.values], directed=True, edge_attrs=['weight'])\n",
    "df = D.head()\n",
    "g = g.as_undirected()\n",
    "g = g.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read vertex attributes and add to graph\n",
    "A = pd.read_csv(datadir+'Airports/airports_loc.csv')\n",
    "lookup = {k:v for v,k in enumerate(A['airport'])}\n",
    "l = [lookup[x] for x in g.vs()['name']]\n",
    "g.vs()['layout'] = [(A['lon'][i],A['lat'][i]) for i in l]\n",
    "g.vs()['state'] = [A['state'][i] for i in l]\n",
    "g.vs()['city'] = [A['city'][i] for i in l]\n",
    "## add a few more attributes for visualization\n",
    "g.vs()['size'] = 6\n",
    "g.vs()['color'] = cls[0]\n",
    "g.es()['color'] = cls_edges\n",
    "df = A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pick a vertex\n",
    "v = 207\n",
    "print(g.degree()[v],g.vs[v])\n",
    "g.vs[v]['color'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show its ego-net\n",
    "sg = g.subgraph([i for i in g.neighborhood(v,order=1)])\n",
    "print(sg.vcount(),'nodes')\n",
    "#ig.plot(sg,'airport_ego_1.eps',bbox=(0,0,300,300))\n",
    "ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show its 2-hops ego-net, this is already quite large!\n",
    "sg = g.subgraph([i for i in g.neighborhood(v,order=2)])\n",
    "sg.vs()['core'] = sg.coreness()\n",
    "sg.delete_vertices([v for v in sg.vs if v['core']<2])\n",
    "print(sg.vcount(),'nodes')\n",
    "#ig.plot(sg,'airport_ego_2.eps',bbox=(0,0,300,300))\n",
    "ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply ensemble clustering, show cluster containing the selected vertex\n",
    "ec = g.community_ecg(ens_size=32)\n",
    "g.es['W'] = ec.W\n",
    "m = ec.membership[v]\n",
    "sg = g.subgraph([i for i in range(g.vcount()) if ec.membership[i]==m])\n",
    "sg.vs()['core'] = sg.coreness()\n",
    "sg.delete_vertices([v for v in sg.vs if v['core']<2])\n",
    "print(sg.vcount(),'nodes')\n",
    "#ig.plot(sg,'airport_ecg.eps',bbox=(0,0,300,300))\n",
    "ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter edges w.r.t. ECG votes (weights)\n",
    "## you can adjust the threshold to get different zooming\n",
    "thresh = .8\n",
    "tmp = sg.subgraph_edges([e for e in sg.es if e['W'] > thresh])\n",
    "n = [i for i in range(tmp.vcount()) if tmp.vs[i]['color']=='black'][0]\n",
    "tmp.vs['cl'] = tmp.clusters().membership\n",
    "cl = tmp.vs[n]['cl']\n",
    "ssg = tmp.subgraph([i for i in tmp.vs if i['cl']==cl])\n",
    "ssg.vs()['core'] = ssg.coreness()\n",
    "ssg.delete_vertices([v for v in ssg.vs if v['core']<2])\n",
    "print(ssg.vcount(),'nodes')\n",
    "#ig.plot(ssg,'airport_ecg_focus.eps',bbox=(0,0,300,300))\n",
    "ig.plot(ssg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## states in the above subgraph\n",
    "Counter(ssg.vs['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABCD Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate new degree and community size values\n",
    "cmd = 'julia '+abcd_path+'deg_sampler.jl deg.dat 2.5 5 15 100 1000'\n",
    "os.system(cmd)\n",
    "cmd = 'julia '+abcd_path+'com_sampler.jl cs.dat 1.5 30 50 100 1000'\n",
    "os.system(cmd);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just for visualization -- push the layout apart given 3 communities\n",
    "def push_layout(d=0):\n",
    "    if np.max(g.vs['comm'])>2:\n",
    "        return -1\n",
    "    ly = g.layout()\n",
    "    g.vs['ly'] = ly\n",
    "    x = [0,0,0]\n",
    "    y = [0,0,0]\n",
    "    for v in g.vs:\n",
    "        c = v['comm']\n",
    "        x[c] += v['ly'][0]\n",
    "        y[c] += v['ly'][1]\n",
    "    delta = [-d,0,d]\n",
    "    dx = [delta[i] for i in np.argsort(x)]\n",
    "    dy = [delta[i] for i in np.argsort(y)]\n",
    "    for v in g.vs:\n",
    "        c = v['comm']\n",
    "        v['ly'][0] += dx[c]\n",
    "        v['ly'][1] += dy[c]\n",
    "    return g.vs['ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## viz: ABCD with very strong communities\n",
    "xi = 0.05\n",
    "cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "        +str(xi)+' false false'\n",
    "os.system(cmd)\n",
    "## compute AMI for various clustering algorithms\n",
    "g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "g.vs['comm'] = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "g.vs['color'] = [cls[i] for i in g.vs['comm']]\n",
    "g.vs['size'] = 5\n",
    "g.es['color'] = 'lightgrey'\n",
    "ly = push_layout(0)\n",
    "ig.plot(g, layout=ly, bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## viz: ABCD with strong communities\n",
    "\n",
    "xi = 0.15\n",
    "cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "        +str(xi)+' false false'\n",
    "os.system(cmd)\n",
    "## compute AMI for various clustering algorithms\n",
    "g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "g.vs['comm'] = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "g.vs['color'] = [cls[i] for i in g.vs['comm']]\n",
    "g.vs['size'] = 5\n",
    "g.es['color'] = 'lightgrey'\n",
    "ly = push_layout(0)\n",
    "ig.plot(g, layout=ly, bbox=(0,0,300,300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## viz: ABCD with weak communities\n",
    "\n",
    "xi = 0.33\n",
    "cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "        +str(xi)+' false false'\n",
    "os.system(cmd)\n",
    "## compute AMI for various clustering algorithms\n",
    "g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "g.vs['comm'] = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "g.vs['color'] = [cls[i] for i in g.vs['comm']]\n",
    "g.vs['size'] = 5\n",
    "g.es['color'] = 'lightgrey'\n",
    "ly = push_layout(3)\n",
    "ig.plot(g, layout=ly, bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## viz: ABCD with very weak communities\n",
    "\n",
    "xi = 0.67\n",
    "cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "        +str(xi)+' false false'\n",
    "os.system(cmd)\n",
    "## compute AMI for various clustering algorithms\n",
    "g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "g.vs['comm'] = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "g.vs['color'] = [cls[i] for i in g.vs['comm']]\n",
    "g.vs['size'] = 5\n",
    "g.es['color'] = 'lightgrey'\n",
    "ly = push_layout(6)\n",
    "ig.plot(g, layout=ly, bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures\n",
    "\n",
    "* We illustrate the importance of using proper adjusted measures when comparing partitions\n",
    "* We generate some ABCD graph and compare ground truth with random partitions of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate new degree and community size values\n",
    "cmd = 'julia '+abcd_path+'deg_sampler.jl deg.dat 2.5 5 50 1000 1000'\n",
    "os.system(cmd)\n",
    "cmd = 'julia '+abcd_path+'com_sampler.jl cs.dat 1.5 75 150 1000 1000'\n",
    "os.system(cmd)\n",
    "xi = .1\n",
    "cmd = 'julia '+abcd_path+'graph_sampler.jl net.dat comm.dat deg.dat cs.dat '\\\n",
    "        +str(xi)+' false false'\n",
    "os.system(cmd)\n",
    "## compute AMI for various clustering algorithms\n",
    "g = ig.Graph.Read_Ncol('net.dat',directed=False)\n",
    "c = np.loadtxt('comm.dat',dtype='uint16',usecols=(1))\n",
    "gt = [c[int(x['name'])-1]-1 for x in g.vs]\n",
    "print(np.max(gt)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAND Index: given two clusterings u and v\n",
    "def RI(u,v):\n",
    "    ## build sets from A and B\n",
    "    a = np.max(u)+1\n",
    "    b = np.max(v)+1\n",
    "    n = len(u)\n",
    "    if n != len(v):\n",
    "        exit -1\n",
    "    A = [set() for i in range(a)]\n",
    "    B = [set() for i in range(b)]\n",
    "    for i in range(n):\n",
    "        A[gt[i]].add(i)\n",
    "        B[r[i]].add(i)   \n",
    "    ## RAND index step by step\n",
    "    R = 0\n",
    "    for i in range(a):\n",
    "        for j in range(b):\n",
    "            s = len(A[i].intersection(B[j]))\n",
    "            if s>1:\n",
    "                R += s*(s-1)/2\n",
    "    R *= 2\n",
    "    for i in range(a):\n",
    "        s = len(A[i])\n",
    "        if s>1:\n",
    "            R -= s*(s-1)/2\n",
    "    for i in range(b):\n",
    "        s = len(B[i])\n",
    "        if s>1:\n",
    "            R -= s*(s-1)/2\n",
    "    R += n*(n-1)/2\n",
    "    R /= n*(n-1)/2\n",
    "    return R\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random clusterings and compute various measures w.r.t. ground truth\n",
    "from sklearn.metrics import mutual_info_score as MI\n",
    "from sklearn.metrics import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "L = []\n",
    "n = g.vcount()\n",
    "ar = np.arange(2,21)\n",
    "for s in ar:\n",
    "    for i in range(100):\n",
    "        r = np.random.choice(s, size=n)\n",
    "        L.append([s,MI(gt,r),NMI(gt,r),AMI(gt,r),RI(gt,r),ARI(gt,r)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mutual information (MI), normalized MI (NMI) and adjusted MI (AMI)\n",
    "\n",
    "D = pd.DataFrame(L,columns=['size','MI','NMI','AMI','RI','ARI'])\n",
    "R = D.groupby(by='size').mean()\n",
    "\n",
    "plt.plot(ar,R['MI'],':',color='black',label='MI')\n",
    "plt.plot(ar,R['NMI'],'--',color='black',label='NMI')\n",
    "plt.plot(ar,R['AMI'],'-',color='black',label='AMI')\n",
    "plt.xlabel('number of random clusters',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('MI.eps');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAND index (RI) and adjusted (ARI)\n",
    "plt.plot(ar,R['RI'],':',color='black',label='RI')\n",
    "plt.plot(ar,R['ARI'],'-',color='black',label='ARI')\n",
    "plt.xlabel('number of random clusters',fontsize=14)\n",
    "plt.legend();\n",
    "#plt.savefig('RI.eps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
