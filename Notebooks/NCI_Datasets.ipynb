{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "* download graph2vec code from  https://github.com/benedekrozemberczki/graph2vec\n",
    "* NCI1 and NCI109 datasets (included)\n",
    "* Modify paths in next cell accordingly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pick one of the two datasets\n",
    "#datadir = '../Datasets/NCI1/'\n",
    "datadir = '../Datasets/NCI109/'\n",
    "\n",
    "## location of graph2vec python code\n",
    "g2v = '../../../graph2vec/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import umap, umap.plot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc \n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets for graph2vec\n",
    "\n",
    "* save each graph in a json file, where the filenames are 0-based integers\n",
    "* each file contains a list of edges and dictionary of node features\n",
    "* graph2vec code from: https://github.com/benedekrozemberczki/graph2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data from NCI folder\n",
    "edges = datadir+'DS_A.txt'\n",
    "graph_id = datadir+'DS_graph_indicator.txt'\n",
    "graph_label = datadir+'DS_graph_labels.txt'\n",
    "node_label = datadir+'DS_node_labels.txt'\n",
    "\n",
    "## read edges, build overall graph\n",
    "X = np.array(pd.read_csv(edges,header=None))\n",
    "E = [list(x) for x in X]\n",
    "G = ig.Graph.TupleList(E, directed=True)\n",
    "\n",
    "## add missing vertices (isolates)\n",
    "vertices = set(G.vs['name'])\n",
    "\n",
    "## read subgraph membership (1-based)\n",
    "m = [int(x) for x in np.array(pd.read_csv(graph_id,header=None))]\n",
    "\n",
    "## add difference\n",
    "v = set(np.arange(1,len(m)+1))\n",
    "diff = v.difference(vertices)\n",
    "G.add_vertices(list(diff))\n",
    "\n",
    "## for plotting\n",
    "G.vs['size'] = 10\n",
    "G.vs['color'] = 'darkgrey'\n",
    "G.es['color'] = 'grey'\n",
    "G.es['arrow_size'] = .33\n",
    "G.vs['label_size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping nodes in order of name\n",
    "idx = list(np.argsort(G.vs['name']))\n",
    "\n",
    "## assign subgraph\n",
    "for i in range(len(m)):\n",
    "    G.vs[idx[i]]['graph'] = m[i]\n",
    "\n",
    "## verify with graph label list\n",
    "l = [G.vs[i]['graph'] for i in idx]\n",
    "l == m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read node labels\n",
    "l = [int(x) for x in np.array(pd.read_csv(node_label,header=None))]\n",
    "for i in range(len(l)):\n",
    "    G.vs[idx[i]]['label'] = l[i]\n",
    "G = G.as_undirected()\n",
    "\n",
    "## read graph labels\n",
    "gl = [int(x) for x in np.array(pd.read_csv(graph_label,header=None))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the subgraphs and save json files in data directory\n",
    "for gp in np.arange(1,np.max(G.vs['graph'])+1):\n",
    "    v = [v for v in G.vs if v['graph']==gp]\n",
    "    sg = G.subgraph(v)\n",
    "    sg_edges = [list(e.tuple) for e in sg.es]\n",
    "    sg_features = {str(v.index):str(v['label']) for v in sg.vs}\n",
    "    sg_json = {\"edges\":sg_edges,\"features\":sg_features}\n",
    "    fn = datadir+str(gp-1)+'.json'\n",
    "    with open(fn,'w') as fp:\n",
    "        json.dump(sg_json,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run graph2vec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run graph2vec \n",
    "cmd = 'python '+g2v+'graph2vec.py --input-path '+datadir+' --output-path '+datadir+\\\n",
    "'NCI.csv --dimensions 1024 --workers 1' \n",
    "x = os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embedding with UMAP\n",
    "\n",
    "color w.r.t. graph label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv(datadir+'NCI.csv')\n",
    "D = np.array(D.drop(columns=['type']))\n",
    "U = umap.UMAP(n_neighbors=15).fit(D)\n",
    "umap.plot.points(U,labels=np.array(gl),theme='viridis',width=800,height=500);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification in embedded space\n",
    "\n",
    "* we use 90% for training, 10% for testing\n",
    "* we try nearest-neighbour and random forest\n",
    "* PROJECT: \n",
    " - divide training set into training and validation \n",
    " - use this to select best model by trying several hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(D, gl, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k nearest neighbours classifier\n",
    "knn_mdl = knn(n_neighbors=5)\n",
    "knn_mdl.fit(X_train,y_train)\n",
    "y_pred = knn_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest classifier\n",
    "rfc_mdl = rfc(n_estimators=500,criterion='entropy')\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC curve\n",
    "y_probs = rfc_mdl.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_probs)\n",
    "auc = metrics.roc_auc_score(y_test, y_probs)\n",
    "plt.plot(fpr,tpr,label=\"ROC, auc=\"+str('%.3f' % auc),color='black')\n",
    "plt.plot([0,1],[0,1],'--',label='Random',color='black')\n",
    "plt.legend(loc=4,fontsize=14)\n",
    "plt.xlabel('False Positive Rate',fontsize=14)\n",
    "plt.ylabel('True Positive Rate',fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgraph features\n",
    "\n",
    "- we compute several statistics on the graphs\n",
    " - number of nodes, edges, density \n",
    " - degree distribution \n",
    " - number of components, size of the giant component\n",
    " - transitivity\n",
    " - degree assortativity\n",
    " - coreness distribution\n",
    " - node labels distribution\n",
    " \n",
    "- we compare those for the two classes of graphs\n",
    "- we perform binary classification using those features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of a graph with label 0\n",
    "gp = 500\n",
    "v = [v for v in G.vs if v['graph']==gp]\n",
    "sg = G.subgraph(v)\n",
    "print('label:',gl[gp-1])\n",
    "ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of a graph with label 1\n",
    "gp = 2000\n",
    "v = [v for v in G.vs if v['graph']==gp]\n",
    "sg = G.subgraph(v)\n",
    "print('label:',gl[gp-1])\n",
    "ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing features fo each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degrees(sg,md):\n",
    "    ctr = Counter(sg.degree())\n",
    "    return [ctr[i] for i in range(md+1)]\n",
    "\n",
    "def core(sg,mc):\n",
    "    ctr = Counter(sg.coreness())\n",
    "    return [ctr[i] for i in range(mc+1)]\n",
    "\n",
    "def labels(sg,ml):\n",
    "    ctr = Counter(sg.vs['label'])\n",
    "    return [ctr[i+1] for i in range(ml)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute features for each graph\n",
    "L = []\n",
    "md = np.max(G.degree())\n",
    "mc = np.max(G.coreness())\n",
    "ml = np.max(G.vs['label'])\n",
    "\n",
    "for gp in np.arange(1,np.max(G.vs['graph'])+1):\n",
    "    v = [v for v in G.vs if v['graph']==gp]\n",
    "    sg = G.subgraph(v)\n",
    "    ## node and edge counts, density\n",
    "    x = [sg.vcount(),sg.ecount(),sg.ecount()/sg.vcount()]\n",
    "    ## number of components, relative size of giant component\n",
    "    x.extend([np.max(sg.clusters().membership)+1,sg.clusters().giant().vcount()/sg.vcount()])\n",
    "    ## transitivity, assortativity\n",
    "    x.extend([sg.transitivity_undirected(),sg.transitivity_avglocal_undirected()])\n",
    "    ## assortativity\n",
    "    a = sg.assortativity_degree()\n",
    "    if np.isnan(a):\n",
    "        a=0\n",
    "    x.extend([a])\n",
    "    ## degree distribution\n",
    "    x.extend(degrees(sg,md))\n",
    "    ## coreness distribution\n",
    "    x.extend(core(sg,mc))\n",
    "    ## node labels distribution\n",
    "    x.extend(labels(sg,ml))\n",
    "    L.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store all features in a dataframe\n",
    "col = ['nodes','edges','density','components','giant','trans','local trans','assort']\n",
    "col.extend(['deg'+str(i) for i in np.arange(md+1)])\n",
    "col.extend(['core'+str(i) for i in np.arange(mc+1)])\n",
    "col.extend(['label'+str(i+1) for i in np.arange(ml)])\n",
    "F = pd.DataFrame(L,columns=col)\n",
    "F['type'] = gl\n",
    "F.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot features\n",
    "\n",
    "we selected a few and compare for graphs for type 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(2,2,figsize=(8,8))\n",
    "plt.subplot(221)\n",
    "sns.boxplot(x='type',y='assort',data=F)\n",
    "plt.subplot(222)\n",
    "sns.boxplot(x='type',y='density',data=F)\n",
    "plt.subplot(223)\n",
    "sns.boxplot(x='type',y='deg3',data=F)\n",
    "plt.subplot(224)\n",
    "sns.boxplot(x='type',y='label3',data=F);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try binary classification with those features\n",
    "## divide data into training and testing\n",
    "A = np.array(F.drop(columns=['type']))\n",
    "X_train, X_test, y_train, y_test = train_test_split(A, gl, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k nearest neighbours classifier\n",
    "knn_mdl = knn(n_neighbors=5)\n",
    "knn_mdl.fit(X_train,y_train)\n",
    "y_pred = knn_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random forest classifier\n",
    "rfc_mdl = rfc(n_estimators=500,criterion='entropy')\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most important features\n",
    "x = np.argsort(rfc_mdl.feature_importances_)\n",
    "top = [x[i] for i in np.arange(len(x)-1,-1,-1)]\n",
    "top_features = [F.columns[i] for i in top]\n",
    "top_features[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
