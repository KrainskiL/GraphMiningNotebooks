{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* python-igraph and plfit\n",
    "* set directories in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import plfit\n",
    "from scipy.stats import poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 -- generating figures from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.1: size of the giant component\n",
    "\n",
    "* this is for a random graph\n",
    "* We try $n=100$ and $n=10000$ below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n=10000\n",
    "gc_avg = []\n",
    "gc_std = []\n",
    "REP = 1000 ## repeats\n",
    "ad = np.arange(.1,10.1,.1)\n",
    "for d in ad:\n",
    "    x = []\n",
    "    for rep in range(REP):\n",
    "        p = d/(n-1)\n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(g.clusters().giant().vcount())\n",
    "    gc_avg.append(np.mean(x))\n",
    "    gc_std.append(np.std(x))\n",
    "\n",
    "## theoretical\n",
    "th = [np.log(n) for i in np.arange(.1,1.1,.1)]\n",
    "from scipy.optimize import fsolve\n",
    "def fn(x,d):\n",
    "    return x+np.exp(-x*d)-1\n",
    "for i in np.arange(1.1,10.1,.1):\n",
    "    th.append(n*fsolve(fn,1,args=(i))[0])\n",
    "\n",
    "plt.fill_between(ad,[x[0]-1.654*x[1] for x in zip(gc_avg,gc_std)],\n",
    "                 [x[0]+1.645*x[1] for x in zip(gc_avg,gc_std)],color='lightgray')\n",
    "plt.plot(ad,th,color='black')\n",
    "plt.xlabel('average degree',fontsize=14)\n",
    "plt.ylabel('giant component size',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.2: P(graph is connected)\n",
    "\n",
    "* again for random graphs\n",
    "* we try $n=100$ and $n=10000$ below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "REP = 1000 ## repeats\n",
    "lo = -int(np.floor(np.log(n)*10))/10\n",
    "if lo<-10:\n",
    "    lo = -10\n",
    "C = np.arange(lo,10.1,.1)\n",
    "ic_avg=[]\n",
    "for c in C:\n",
    "    x = []\n",
    "    for rep in range(REP):\n",
    "        p = (c+np.log(n))/n\n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(int(g.is_connected()))\n",
    "    ic_avg.append(np.mean(x))\n",
    "\n",
    "## theoretical\n",
    "th = [np.exp(-np.exp(-c)) for c in C]\n",
    "\n",
    "## plot\n",
    "plt.fill_between(C,[x-1.654*np.sqrt(x*(1-x)/n) for x in ic_avg],\n",
    "                 [x+1.645*np.sqrt(x*(1-x)/n) for x in ic_avg],color='lightgray')\n",
    "plt.plot(C,th,color='black')\n",
    "plt.xlabel(r'constant $c$',fontsize=14)\n",
    "plt.ylabel('P(graph is connected)',fontsize=14);\n",
    "#plt.savefig('connected_100.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.4: Distribution of shortest path lengths\n",
    "\n",
    "For random graphs of varying size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = []\n",
    "N = [50,100,200,400,800,1600,3200]\n",
    "for n in N:\n",
    "    p = 5/(n-1)\n",
    "    g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "    z = g.shortest_paths()\n",
    "    sp.append([x for y in z for x in y])\n",
    "## plot    \n",
    "plt.boxplot(sp, labels=N, sym='.',whis=5);\n",
    "# plt.savefig('path_len.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.5 Poisson vs degree distributions\n",
    "\n",
    "* for random graphs\n",
    "* we try $n=100$ and $n=10000$ below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "p = 10/(n-1)\n",
    "g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "x = [x[0] for x in sorted(Counter(g.degree()).items())]\n",
    "pmf = [poisson.pmf(k,10) for k in x]\n",
    "frq = [x[1]/n for x in sorted(Counter(g.degree()).items())]\n",
    "plt.plot(x,frq,'o',color='black')\n",
    "plt.plot(x,pmf,':',color='black')\n",
    "plt.xlabel('degree',fontsize=14)\n",
    "plt.ylabel('frequency/pmf',fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.6 --  Power law graphs\n",
    "\n",
    "* We generate a power law graph and use the 'plfit' package to model its degree distribution.\n",
    "* We use the Chung-Lu model, so there can be isolated nodes\n",
    "* We do not use 0-degree nodes as they yield errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fast Chung-Lu: generate m edges w.r.t. distribution d\n",
    "def fastCL(d, m):\n",
    "    n = len(d)\n",
    "    s = np.sum(d)\n",
    "    p = [i/s for i in d]\n",
    "    target = m\n",
    "    tples = []\n",
    "    while len(tples) < target:\n",
    "        s = target - len(tples)\n",
    "        e0 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        e1 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        tples.extend([(min(e0[i],e1[i]),max(e0[i],e1[i])) for i in range(len(e0)) if e0[i]!=e1[i]]) ## ignore loops\n",
    "        tples = list(set(tples)) ## drop collisions\n",
    "    return tples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## power law graph\n",
    "gamma = 2.5\n",
    "n = 10000\n",
    "delta = 1\n",
    "Delta = np.sqrt(n)\n",
    "W = []\n",
    "for i in np.arange(1,n+1):\n",
    "    W.append(delta * (n/(i-1+n/(Delta/delta)**(gamma-1)))**(1/(gamma-1)))\n",
    "\n",
    "deg = [int(np.round(w)) for w in W]\n",
    "m = int(np.mean(deg)*n/2)\n",
    "tpl = fastCL(deg,m)\n",
    "g1 = ig.Graph.TupleList(tpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of isolated nodes\n",
    "iso = n-g1.vcount()\n",
    "print('isolates:',iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = g1.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS test, this can be slow ...\n",
    "X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(1)\n",
    "ax = X.alphavsks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(2)\n",
    "ax = X.plotpdf(plcolor='k',histcolor='grey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = plt.figure(4)\n",
    "X.plotcdf(pointcolor='grey', pointmarker='.',zoom=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.7: simple d-regular graphs\n",
    "\n",
    "* We empirically compute the probability that a d-regular graph is simple.\n",
    "* we use n=100 and n=10000 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "REP = 100\n",
    "D = np.arange(2,11) \n",
    "simple = []\n",
    "for d in D:\n",
    "    x = 0\n",
    "    for rep in range(REP):\n",
    "        g = ig.Graph.Degree_Sequence([d for i in range(n)])\n",
    "        x += int(g.is_simple())\n",
    "    simple.append(x/REP)\n",
    "th = [np.exp(-(d*d-1)/4) for d in D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D,simple,'o',color='black')\n",
    "plt.plot(D,th,':',color='black')\n",
    "plt.xlabel('degree',fontsize=14)\n",
    "plt.ylabel('P(graph is simple)',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 -- Experiments section\n",
    "\n",
    "* We consider a real graph and compare some statistics with random graphs. \n",
    "* We use the GitHub ml developers graph that we introduced in Chapter 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the GitHub edge list into a graph (gh)\n",
    "\n",
    "D = pd.read_csv(datadir+'GitHubDevelopers/musae_git_edges.csv')\n",
    "tuples = [tuple(x) for x in D.values]\n",
    "gh = ig.Graph.TupleList(tuples, directed = False)\n",
    "\n",
    "## Add some node features;\n",
    "## There are 2 class of nodes\n",
    "## 0: web developer (red), 1: ml developer (blue)\n",
    "\n",
    "X = pd.read_csv(datadir+'GitHubDevelopers/musae_git_target.csv')\n",
    "idx = [int(i) for i in gh.vs['name']]\n",
    "sorterIndex = dict(zip(idx,range(len(idx))))\n",
    "X['Rank'] = X['id'].map(sorterIndex)\n",
    "X.sort_values(['Rank'], ascending=[True],inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "gh.vs['target'] = list(X['ml_target'])\n",
    "cls = ['grey','black']\n",
    "gh.vs['color'] = [cls[i] for i in list(X['ml_target'])]\n",
    "gh.es['color'] = 'grey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for github, 9739 are ml developers, build the subgraph\n",
    "gh_ml = gh.subgraph([v for v in gh.vs() if v['color']=='black'])\n",
    "\n",
    "## keep the giant component\n",
    "sg = gh_ml.clusters().giant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute some graph stats\n",
    "S = []\n",
    "deg = sg.degree()\n",
    "S.append(['Base Graph',sg.vcount(),sg.ecount(),np.min(deg),np.mean(deg),np.median(deg),\n",
    "      np.max(deg),sg.diameter(),np.max(sg.clusters().membership)+1,sg.clusters().giant().vcount(),\n",
    "         sum([x==0 for x in sg.degree()]),sg.transitivity_undirected(),sg.transitivity_avglocal_undirected()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random (Erdos-Renyi) graph with same number of nodes and edges\n",
    "er = ig.Graph.Erdos_Renyi(n=sg.vcount(), m=sg.ecount())\n",
    "deg = er.degree()\n",
    "S.append(['Erdos-Renyi',er.vcount(),er.ecount(),np.min(deg),np.mean(deg),np.median(deg),\n",
    "      np.max(deg),er.diameter(),np.max(er.clusters().membership)+1,er.clusters().giant().vcount(),\n",
    "         sum([x==0 for x in er.degree()]),er.transitivity_undirected(),er.transitivity_avglocal_undirected()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random (Chung-Lu) graph with same degree distribution\n",
    "tpl = fastCL(sg.degree(),sg.ecount()) \n",
    "cl = ig.Graph.Erdos_Renyi(n=sg.vcount(),m=0)\n",
    "cl.add_edges(tpl)\n",
    "deg = cl.degree()\n",
    "S.append(['Chung-Lu',cl.vcount(),cl.ecount(),np.min(deg),np.mean(deg),np.median(deg),\n",
    "      np.max(deg),cl.diameter(),np.max(cl.clusters().membership)+1,cl.clusters().giant().vcount(),\n",
    "         sum([x==0 for x in cl.degree()]),cl.transitivity_undirected(),cl.transitivity_avglocal_undirected()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random (configuration model) graph with same degree distribution\n",
    "cm = ig.Graph.Degree_Sequence(sg.degree(),method='simple')\n",
    "deg = cm.degree()\n",
    "S.append(['Configuration',cm.vcount(),cm.ecount(),np.min(deg),np.mean(deg),np.median(deg),\n",
    "      np.max(deg),cm.diameter(),np.max(cm.clusters().membership)+1,cm.clusters().giant().vcount(),\n",
    "         sum([x==0 for x in cm.degree()]),cm.transitivity_undirected(),cm.transitivity_avglocal_undirected()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random graph with same degree distribution using the\n",
    "## configuration model with VL method, which yield a simple graph\n",
    "cmvl = ig.Graph.Degree_Sequence(sg.degree(),method='vl')\n",
    "deg = cmvl.degree()\n",
    "S.append(['Configuration (VL)',cmvl.vcount(),cmvl.ecount(),np.min(deg),np.mean(deg),np.median(deg),\n",
    "      np.max(deg),cmvl.diameter(),np.max(cmvl.clusters().membership)+1,cmvl.clusters().giant().vcount(),\n",
    "         sum([x==0 for x in cmvl.degree()]),cmvl.transitivity_undirected(),cmvl.transitivity_avglocal_undirected()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare results\n",
    "D = pd.DataFrame(S,columns=['graph','nodes','edges',r'$d_{min}$',r'$d_{mean}$',\n",
    "                             r'$d_{median}$',r'$d_{max}$','diameter','components','largest','isolates',\n",
    "                             r'$C_{glob}$',r'$C_{loc}$'])\n",
    "D = D.transpose()\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To produce LaTeX from a DataFrame\n",
    "#df = D.round(decimals=3)\n",
    "#print(df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute min path length for every node pair for the 5 graphs (real and 4 random ones)\n",
    "cl_g = cl.clusters().giant()\n",
    "cm_g = cm.clusters().giant()\n",
    "V = np.random.choice(cl_g.vcount(),size=500,replace=False) ## sampling is faster\n",
    "# V = cl_g.vs() ## doing all vertices is slower\n",
    "\n",
    "sp_sg = []\n",
    "sp_er = []\n",
    "sp_cl = []\n",
    "sp_cm = []\n",
    "sp_cmvl = []\n",
    "for v in V:\n",
    "    sp_sg.extend(sg.shortest_paths(source=v)[0])\n",
    "    sp_er.extend(er.shortest_paths(source=v)[0])\n",
    "    sp_cl.extend(cl_g.shortest_paths(source=v)[0])\n",
    "    sp_cm.extend(cm_g.shortest_paths(source=v)[0])\n",
    "    sp_cmvl.extend(cmvl.shortest_paths(source=v)[0])\n",
    "    \n",
    "plt.boxplot([sp_sg,sp_er,sp_cl,sp_cm,sp_cmvl],labels=['Base','ER','CL','CM','CM-VL'],\n",
    "            sym='.',whis=10, medianprops = dict(linestyle='-', linewidth=2.5,color='black'))\n",
    "plt.ylabel('shortest path length',fontsize=14);\n",
    "#plt.savefig('pathlen_box.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More power law - Grid and GitHub graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for github, 9739 are ml developers, build the subgraph\n",
    "gh_ml = gh.subgraph([v for v in gh.vs() if v['color']=='black'])\n",
    "## keep the giant component\n",
    "sg = gh_ml.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS test -- very good fit here\n",
    "X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for github, 9739 are ml developers, build the subgraph\n",
    "gh_web = gh.subgraph([v for v in gh.vs() if v['color']!='black'])\n",
    "## keep the giant component\n",
    "sg = gh_web.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS test -- not as good as previous graph, but still significant\n",
    "X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read edge list for the grid network\n",
    "gr = ig.Graph.Read_Ncol(datadir+'GridEurope/gridkit_europe-highvoltage.edges', directed=False)\n",
    "gr = gr.simplify()\n",
    "## keep the giant component\n",
    "sg = gr.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we get xmin=15 ... how many nodes does this cover? --> just a few!\n",
    "sum([x>=15 for x in sg.degree()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's fix xmin=4 \n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit(xmin=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS test -- clearly not a good fit\n",
    "X.test_pl(niter=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
