{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will install required Python packages. It needs to be run only once:\n",
    "```\n",
    "using PyCall\n",
    "run(`$(PyCall.python) -m pip install python-igraph`)\n",
    "run(`$(PyCall.python) -m pip install umap-learn`)\n",
    "run(`$(PyCall.python) -m pip install sklearn`)\n",
    "run(`$(PyCall.python) -m pip install partition_igraph`)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we also show how to use both LightGraphs.jl and igraph from Julia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* set the directories in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set those accordingly\n",
    "datadir = \"../Datasets/\"\n",
    "abcd_path = \"~/ABCD/utils/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LightGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GraphPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FreqTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ABCDGraphGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = pyimport(\"igraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = pyimport(\"umap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_igraph = pyimport(\"partition_igraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMI = pyimport(\"sklearn.metrics\").adjusted_mutual_info_score\n",
    "MI = pyimport(\"sklearn.metrics\").mutual_info_score\n",
    "ARI = pyimport(\"sklearn.metrics\").adjusted_rand_score\n",
    "NMI = pyimport(\"sklearn.metrics\").normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zachary (karate) graph\n",
    "\n",
    "A small graph with 34 nodes and two \"ground-truth\" communities;\n",
    "modularity-based algorithms will typically find 4 or 5 communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(2)\n",
    "z_lg = smallgraph(:karate)\n",
    "comm = [0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1] .+ 1 # we match Python class labels\n",
    "col = [\"red\", \"green\"]\n",
    "gplot(z_lg,\n",
    "      NODESIZE=0.06, nodefillc=col[comm],\n",
    "      EDGELINEWIDTH=0.2, edgestrokec=\"gray\",\n",
    "      nodelabel=0:nv(z_lg)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node roles --\n",
    " \n",
    "We compute z(v) (normalized within module degree) and p(v) (participation coefficients) as defined in section 5.2 of the book. \n",
    "\n",
    "We identify 3 types of nodes\n",
    "\n",
    "* provincial hubs\n",
    "* peripheral nodes (non-hubs)\n",
    "* ultra peripheral nodes (non-hubs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df = DataFrame(id = 0:nv(z_lg)-1, comm=comm, deg=degree(z_lg), in_deg=0)\n",
    "for e in edges(z_lg)\n",
    "    src, dst = e.src, e.dst\n",
    "    if z_df.comm[src] == z_df.comm[dst]\n",
    "        z_df.in_deg[src] += 1\n",
    "        z_df.in_deg[dst] += 1\n",
    "    end\n",
    "end\n",
    "z_df.out_deg = z_df.deg - z_df.in_deg\n",
    "transform!(groupby(z_df, :comm), :in_deg => (x -> (x .- mean(x)) / std(x, corrected=false)) => :z);\n",
    "z_df.p = @. 1 - (z_df.in_deg / z_df.deg)^2 - (z_df.out_deg / z_df.deg)^2\n",
    "first(sort!(z_df, :z, rev=true), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(2)\n",
    "col = [z < 2.5 ? (p < 0.62 ? (p < 0.05 ? \"red\" : # ultra peripherial\n",
    "                                         \"blue\") : # peripherial\n",
    "                             \"black\") : # should not happen\n",
    "                 (p < 0.3 ? \"green\" : # hub\n",
    "                            \"black\") # should not happen\n",
    "       for (z, p) in zip(z_df.z, z_df.p)]\n",
    "gplot(z_lg,\n",
    "      NODESIZE=0.06, nodefillc=col,\n",
    "      EDGELINEWIDTH=0.2, edgestrokec=\"gray\",\n",
    "      nodelabel=0:nv(z_lg)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots(figsize=(12,9))\n",
    "scatter(z_df.p,z_df.z, marker=\"o\", s=75, color=col)\n",
    "\n",
    "plot([0, .5], [2.5, 2.5], color=\"k\", linestyle=\"-\", linewidth=2)\n",
    "plot([.05, .05], [-1.0, 2.4], color=\"k\", linestyle=\"-\", linewidth=2)\n",
    "\n",
    "for i in 1:nrow(z_df)\n",
    "    annotate(string(z_df.id[i]), (z_df.p[i]-0.003, z_df.z[i] + 0.07))\n",
    "end\n",
    "\n",
    "xlabel(\"participation coefficient (p)\",fontsize=16)\n",
    "ylabel(\"normalized within module degree (z)\",fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the communities w.r.t. strong/weak definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## strong criterion: internal degree is larger for each node\n",
    "## only two nodes do not qualify\n",
    "z_df[z_df.in_deg .<= z_df.out_deg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## weak criterion: total internal degree > total external degree\n",
    "## both communities satisfy this criterion\n",
    "combine(groupby(z_df, :comm, sort=true), [:in_deg, :out_deg] .=> sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering and dendrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to iGraph with the same graph\n",
    "z = ig.Graph.Famous(\"zachary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Girvan-Newman algorithm\n",
    "gn = z.community_edge_betweenness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"LINES\"] = 40\n",
    "\n",
    "# data frame showing assignment of vertices to clusters as a function of number of clusters\n",
    "DataFrame([gn.as_clustering(i).membership for i in 34:-1:1], Symbol.(34:-1:1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"LINES\"] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute modularity at each possible cut\n",
    "q = [z.modularity(gn.as_clustering(i)) for i in 1:34]\n",
    "plt.plot(1:34,q,\"o-\",color=\"black\")\n",
    "plt.xlabel(\"number of clusters\",fontsize=14)\n",
    "plt.ylabel(\"modularity\",fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show result with 2 clusters -- only 1 node is misclassified\n",
    "println(\"AMI: \", AMI(z_df.comm[sortperm(z_df.id)], gn.as_clustering(2).membership))\n",
    "println(\"q: \", z.modularity(gn.as_clustering(2).membership))\n",
    "freqtable(z_df.comm[sortperm(z_df.id)], gn.as_clustering(2).membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show result with optimal modularity (5 clusters)\n",
    "println(\"AMI: \", AMI(z_df.comm[sortperm(z_df.id)], gn.as_clustering(5).membership))\n",
    "println(\"q: \", z.modularity(gn.as_clustering(5).membership))\n",
    "freqtable(z_df.comm[sortperm(z_df.id)], gn.as_clustering(5).membership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD graph with 100 nodes\n",
    "\n",
    "This graph has 3 communities; with hierarchical clustering, we compare modularity and AMI for each possible cut.\n",
    "\n",
    "Parameters: gamma=3, tau=2, degree range [5,15], comm size range [25,50], xi=.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "g = ig.Graph.Read_Ncol(datadir * \"ABCD/abcd_100.dat\", directed=false)\n",
    "c_raw = parse.(Int, getindex.(split.(readlines(datadir*\"ABCD/abcd_100_comms.dat\")), 2))\n",
    "c = [c_raw[parse(Int, v.attributes()[\"name\"])] for v in g.vs]\n",
    "\n",
    "g_lg = SimpleGraph(100)\n",
    "for line in readlines(datadir * \"ABCD/abcd_100.dat\")\n",
    "    add_edge!(g_lg, parse.(Int, split(line))...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(2)\n",
    "gplot(g_lg,\n",
    "      NODESIZE=0.03, nodefillc=[\"red\", \"green\", \"blue\"][c_raw],\n",
    "      EDGELINEWIDTH=0.2, edgestrokec=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman algorithm -- modularity and AMI for each cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = g.community_edge_betweenness()\n",
    "q = [g.modularity(gn.as_clustering(i)) for i in 1:g.vcount()]\n",
    "a = [AMI(c, gn.as_clustering(i).membership) for i in 1:g.vcount()]\n",
    "plot(1:g.vcount(),q,\".-\",color=\"black\",label=\"modularity\")\n",
    "plot(1:g.vcount(),a,\".-\",color=\"grey\",label=\"AMI\")\n",
    "xlabel(\"number of clusters\",fontsize=14)\n",
    "ylabel(\"modularity or AMI\",fontsize=14)\n",
    "legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(q=q, AMI=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AMI\n",
    "g_gn = gn.as_clustering(n=3).membership\n",
    "println(\"AMI: \",AMI(c, g_gn))\n",
    "println(\"q: \",g.modularity(g_gn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what would we get with 4 clusters?\n",
    "## we see a few nodes get splitted from one community\n",
    "freqtable(c, gn.as_clustering(n=4).membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## those form a triangle\n",
    "cluster3 = [parse(Int, v.attributes()[\"name\"]) for (m, v) in zip(gn.as_clustering(n=4).membership, g.vs) if m == 3]\n",
    "gplot(induced_subgraph(g_lg, cluster3)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABCD with varying xi\n",
    "\n",
    "Here we show a typical way to compare graph clustering using benchmark graphs. \n",
    "\n",
    "We pick some model, here ABCD, and we vary the noise parameter (0 <= xi <= 1). \n",
    "\n",
    "With ABCD, the larger xi is, the closer we are to a random Chung-Lu or configuration model graph (i.e. where only the degree distribution matters). \n",
    "\n",
    "For xi=0, we get pure communities (all edges are internal).\n",
    "\n",
    "We show how to load a pickle file created in Python (detailed codes for generating this file are given in the Python notebooks section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle = pyimport(\"pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = py\"open\"(datadir * \"ABCD/abcd_study.pkl\", \"rb\")\n",
    "L = pickle.load(fh)\n",
    "fh.close()\n",
    "D = DataFrame(L, [:algo, :xi, :AMI])\n",
    "X = combine(groupby(D, [:algo, :xi], sort=true), :AMI => mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = [\"ECG\",\"Louvain\",\"Infomap\",\"Label Prop.\"]\n",
    "lt = [\"-\",\"--\",\":\",\"-.\",\"--\",\":\"]\n",
    "cl = [\"blue\",\"green\",\"purple\",\"red\",\"red\",\"blue\"]\n",
    "for i in eachindex(a)\n",
    "    plot(X[X.algo .== a[i], :AMI_mean], lt[i], label=a[i], color=cl[i])\n",
    "end\n",
    "xlabel(\"ABCD noise (xi)\",fontsize=14)\n",
    "ylabel(\"AMI\",fontsize=14)\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Look at standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = combine(groupby(D, [:algo, :xi], sort=true), :AMI => std)\n",
    "a = [\"ECG\",\"Louvain\",\"Infomap\",\"Label Prop.\"]\n",
    "lt = [\"-\",\"--\",\":\",\"-.\",\"--\",\":\"]\n",
    "cl = [\"blue\",\"green\",\"purple\",\"red\",\"red\",\"blue\"]\n",
    "for i in eachindex(a)\n",
    "    plot(S[S.algo .== a[i], :AMI_std], lt[i], label=a[i], color=cl[i])\n",
    "end\n",
    "xlabel(\"ABCD noise (xi)\",fontsize=14)\n",
    "ylabel(\"Standard Deviation (AMI)\",fontsize=14)\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare stability \n",
    "\n",
    "This study is similar to the previous one, but we compare successive partitions for each algorithm instead of comparing with the ground truth.\n",
    "\n",
    "We show how to load a pickle file created in Python (detailed codes for generating this file are given in the Python notebooks section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load L and train/val/test ids\n",
    "fh = py\"open\"(datadir * \"ABCD/abcd_study_stability.pkl\", \"rb\")\n",
    "Ls = pickle.load(fh)\n",
    "fh.close()\n",
    "\n",
    "## store in dataframe and take averages\n",
    "D = DataFrame(Ls, [:algo,:xi,:AMI])\n",
    "X = combine(groupby(D, [:algo, :xi], sort=true), :AMI => mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"ECG\",\"Louvain\",\"Infomap\",\"Label Prop.\"]\n",
    "lt = [\"-\",\"--\",\":\",\"-.\"]\n",
    "cl = [\"blue\",\"green\",\"purple\",\"red\",\"red\",\"blue\"]\n",
    "for i in eachindex(a)\n",
    "    plot(X[X.algo .== a[i], :AMI_mean], lt[i], label=a[i], color=cl[i])\n",
    "end\n",
    "xlabel(\"ABCD noise (xi)\",fontsize=14)\n",
    "ylabel(\"AMI between successive runs\",fontsize=14)\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity, resolution limit and rings of cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n cliques of size s\n",
    "function ringOfCliques(n,s)\n",
    "    roc = SimpleGraph(n*s)\n",
    "    ## cliques    \n",
    "    for i in 0:n-1, j in s*i:s*(i+1)-1, k in j+1:s*(i+1)-1\n",
    "        add_edge!(roc, j+1, k+1)\n",
    "    end\n",
    "    ## ring\n",
    "    for i in 0:n-1\n",
    "        add_edge!(roc, s*i, s*i+1)\n",
    "    end\n",
    "    add_edge!(roc, n*s, 1)\n",
    "    return roc\n",
    "end\n",
    "\n",
    "## Ex: 10 3-cliques\n",
    "roc = ringOfCliques(10,3)\n",
    "gplot(roc, layout=spectral_layout,\n",
    "      NODESIZE=0.03,\n",
    "      EDGELINEWIDTH=0.1, edgestrokec=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "\n",
    "def ringOfCliques(n,s):\n",
    "    roc = ig.Graph.Erdos_Renyi(n=n*s,p=0)\n",
    "    ## cliques\n",
    "    for i in range(n):\n",
    "        for j in np.arange(s*i,s*(i+1)):\n",
    "            for k in np.arange(j+1,s*(i+1)):\n",
    "                roc.add_edge(j,k)\n",
    "    ## ring\n",
    "    for i in range(n):\n",
    "        if i>0:\n",
    "            roc.add_edge(s*i-1,s*i)\n",
    "        else:\n",
    "            roc.add_edge(n*s-1,0)\n",
    "    return roc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare number of cliques and number of clusters found\n",
    "D = DataFrame(n=Int[], Louvain=Int[], ECG=Int[], CNM=Int[])\n",
    "s = 3\n",
    "for n in 3:3:48\n",
    "    roc = py\"ringOfCliques\"(n,s)\n",
    "    ml = maximum(roc.community_multilevel().membership) + 1\n",
    "    ec = maximum(roc.community_ecg().membership) + 1\n",
    "    cnm = maximum(roc.community_fastgreedy().as_clustering().membership) + 1\n",
    "    push!(D, [n,ml,ec,cnm])\n",
    "end\n",
    "\n",
    "plot(D.n, D.Louvain, \"--o\",color=\"black\", label=\"Louvain\")\n",
    "plot(D.n, D.ECG, \"-o\", color=\"black\",label=\"ECG\")\n",
    "plot(D.n, D.CNM, \":o\", color=\"black\",label=\"CNM\")\n",
    "\n",
    "xlabel(\"number of $s-cliques\",fontsize=14)\n",
    "ylabel(\"number of clusters found\",fontsize=14)\n",
    "legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Louvain communities with 10 3-cliques\n",
    "roc = py\"ringOfCliques\"(n=10,s=3)\n",
    "membership = roc.community_multilevel().membership .+ 1\n",
    "\n",
    "roc = ringOfCliques(10,3) # this time igraph and LightGraphs node indices match\n",
    "gplot(roc, layout=spectral_layout,\n",
    "      nodefillc=[\"red\", \"green\", \"blue\", \"orange\", \"purple\"][membership],\n",
    "      NODESIZE=0.03,\n",
    "      EDGELINEWIDTH=0.1, edgestrokec=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ECG weights in this case: all 30 clique edges have max score\n",
    "freqtable(py\"ringOfCliques\"(n=10,s=3).community_ecg().W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ego nets and more\n",
    "\n",
    "* we consider the airport graph we already saw\n",
    "* we consider a simple, undirected version (no loops, directions or edge weights)\n",
    "* we compare ego-nets (1 and 2-hops subgraphs from a given node) with clusters obtained via graph clustering\n",
    "\n",
    "As above since some algorithms are available only in Python we show how to use iGraph from Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "\n",
    "datadir = \"../Datasets/\"\n",
    "\n",
    "D = pd.read_csv(datadir+'Airports/connections.csv')\n",
    "g = ig.Graph.TupleList([tuple(x) for x in D.values], directed=True, edge_attrs=['weight'])\n",
    "g = g.as_undirected()\n",
    "g = g.simplify()\n",
    "\n",
    "## read vertex attributes and add to graph\n",
    "A = pd.read_csv(datadir+'Airports/airports_loc.csv')\n",
    "lookup = {k:v for v,k in enumerate(A['airport'])}\n",
    "l = [lookup[x] for x in g.vs()['name']]\n",
    "g.vs()['layout'] = [(A['lon'][i],A['lat'][i]) for i in l]\n",
    "g.vs()['state'] = [A['state'][i] for i in l]\n",
    "g.vs()['city'] = [A['city'][i] for i in l]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pick a vertex\n",
    "py\"\"\"\n",
    "v = 207\n",
    "\"\"\"\n",
    "\n",
    "py\"g.degree()[v],g.vs[v]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show its ego-net\n",
    "sg = py\"g.subgraph([i for i in g.neighborhood(v,order=1)])\"\n",
    "println(sg.vcount(), \" nodes\")\n",
    "#ig.plot(sg,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = SimpleGraph(sg.vcount())\n",
    "for e in sg.es()\n",
    "    add_edge!(g, e.source + 1, e.target + 1)\n",
    "end\n",
    "Random.seed!(1)\n",
    "gplot(g, nodefillc= [n.attributes()[\"name\"] == \"MQT\" ? \"black\" : \"red\" for n in sg.vs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show its 2-hops ego-net, this is already quite large!\n",
    "py\"\"\"\n",
    "sg = g.subgraph([i for i in g.neighborhood(v,order=2)])\n",
    "sg.vs()['core'] = sg.coreness()\n",
    "sg.delete_vertices([v for v in sg.vs if v['core']<2])\n",
    "\"\"\"\n",
    "sg = py\"sg\"\n",
    "println(sg.vcount(), \" nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = SimpleGraph(sg.vcount())\n",
    "for e in sg.es()\n",
    "    add_edge!(g, e.source + 1, e.target + 1)\n",
    "end\n",
    "# selected node is larger\n",
    "Random.seed!(3)\n",
    "gplot(g, NODESIZE=[n.attributes()[\"name\"] == \"MQT\" ? 0.05 : 0.01 for n in sg.vs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply clustering, show cluster containing the selected vertex\n",
    "## recall that we ignore edge weights\n",
    "py\"\"\"\n",
    "ec = g.community_ecg(ens_size=32)\n",
    "g.es['W'] = ec.W\n",
    "m = ec.membership[v]\n",
    "sg = g.subgraph([i for i in range(g.vcount()) if ec.membership[i]==m])\n",
    "sg.vs()['core'] = sg.coreness()\n",
    "## display the 2-core\n",
    "sg.delete_vertices([v for v in sg.vs if v['core']<2])\n",
    "\"\"\"\n",
    "sg = py\"sg\"\n",
    "println(sg.vcount(),\" nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = SimpleGraph(sg.vcount())\n",
    "for e in sg.es()\n",
    "    add_edge!(g, e.source + 1, e.target + 1)\n",
    "end\n",
    "# selected node is larger\n",
    "Random.seed!(3)\n",
    "gplot(g, NODESIZE=[n.attributes()[\"name\"] == \"MQT\" ? 0.05 : 0.01 for n in sg.vs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py\"\"\"\n",
    "## filter edges w.r.t. ECG votes (weights)\n",
    "## you can adjust the threshold to get different zooming\n",
    "thresh = .9\n",
    "tmp = sg.subgraph_edges([e for e in sg.es if e['W'] > thresh])\n",
    "n = [i for i in range(tmp.vcount()) if tmp.vs[i]['name']=='MQT'][0]\n",
    "tmp.vs['cl'] = tmp.clusters().membership\n",
    "cl = tmp.vs[n]['cl']\n",
    "ssg = tmp.subgraph([i for i in tmp.vs if i['cl']==cl])\n",
    "ssg.vs()['core'] = ssg.coreness()\n",
    "ssg.delete_vertices([v for v in ssg.vs if v['core']<2])\n",
    "\"\"\"\n",
    "\n",
    "ssg = py\"ssg\"\n",
    "println(ssg.vcount(), \" nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = SimpleGraph(ssg.vcount())\n",
    "for e in ssg.es()\n",
    "    add_edge!(g, e.source + 1, e.target + 1)\n",
    "end\n",
    "Random.seed!(1)\n",
    "gplot(g, nodefillc = [n.attributes()[\"name\"] == \"MQT\" ? \"black\" : \"red\" for n in ssg.vs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## states in the above subgraph\n",
    "freqtable([n.attributes()[\"state\"] for n in ssg.vs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABCD Properties\n",
    "\n",
    "We show ABCD graphs with different xi (noise) parameters;\n",
    "\n",
    "This is for illustration purpose only:\n",
    "\n",
    "* notice the density of edges between communities as xi increases.\n",
    "* most runs should yield 3 communities, but this can vary when we re-run ABCD samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs = ABCDGraphGenerator.sample_degrees(2.5, 5, 15, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms = ABCDGraphGenerator.sample_communities(1.5, 30, 50, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.05\n",
    "g_src = ABCDGraphGenerator.gen_graph(ABCDGraphGenerator.ABCDParams(degs, coms, nothing, xi, false, false))\n",
    "g = SimpleGraph(100)\n",
    "for e in g_src.edges\n",
    "    add_edge!(g, e...)\n",
    "end\n",
    "gplot(g, nodefillc=[\"red\", \"green\", \"blue\"][g_src.clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.15\n",
    "g_src = ABCDGraphGenerator.gen_graph(ABCDGraphGenerator.ABCDParams(degs, coms, nothing, xi, false, false))\n",
    "g = SimpleGraph(100)\n",
    "for e in g_src.edges\n",
    "    add_edge!(g, e...)\n",
    "end\n",
    "gplot(g, nodefillc=[\"red\", \"green\", \"blue\"][g_src.clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.33\n",
    "g_src = ABCDGraphGenerator.gen_graph(ABCDGraphGenerator.ABCDParams(degs, coms, nothing, xi, false, false))\n",
    "g = SimpleGraph(100)\n",
    "for e in g_src.edges\n",
    "    add_edge!(g, e...)\n",
    "end\n",
    "gplot(g, nodefillc=[\"red\", \"green\", \"blue\"][g_src.clusters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.5\n",
    "g_src = ABCDGraphGenerator.gen_graph(ABCDGraphGenerator.ABCDParams(degs, coms, nothing, xi, false, false))\n",
    "g = SimpleGraph(100)\n",
    "for e in g_src.edges\n",
    "    add_edge!(g, e...)\n",
    "end\n",
    "gplot(g, nodefillc=[\"red\", \"green\", \"blue\"][g_src.clusters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures\n",
    "\n",
    "* We illustrate the importance of using proper adjusted measures when comparing partitions\n",
    "* We generate some ABCD graph and compare ground truth with random partitions of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs = ABCDGraphGenerator.sample_degrees(2.5, 5, 50, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms = ABCDGraphGenerator.sample_communities(1.5, 75, 150, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = 0.1\n",
    "g_src = ABCDGraphGenerator.gen_graph(ABCDGraphGenerator.ABCDParams(degs, coms, nothing, xi, false, false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = ig.Graph.Erdos_Renyi(n=1000,p=0)\n",
    "for (from, to) in g_src.edges\n",
    "    gp.add_edge(from-1, to-1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = g_src.clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAND Index: given two clusterings u and v\n",
    "function RI(u,v)\n",
    "    @assert length(u) == length(v)\n",
    "    \n",
    "    n = length(u)\n",
    "    ## build sets from A and B\n",
    "    minu, maxu = extrema(u)\n",
    "    minv, maxv = extrema(v)\n",
    "    A = [Set(findall(==(i), u)) for i in minu:maxu]\n",
    "    B = [Set(findall(==(i), v)) for i in minv:maxv]\n",
    "\n",
    "    ## RAND index step by step\n",
    "    R = 0.0\n",
    "    for sa in A, sb in B\n",
    "        s = length(intersect(sa, sb))\n",
    "        R += s*(s-1)\n",
    "    end\n",
    "    for sa in A\n",
    "        s = length(sa)\n",
    "        R -= s*(s-1)/2\n",
    "    end\n",
    "    for sb in B\n",
    "        s = length(sb)\n",
    "        R -= s*(s-1)/2\n",
    "    end\n",
    "    R += n*(n-1)/2\n",
    "    R /= n*(n-1)/2\n",
    "    return R\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DataFrame(size=Int[], MI=Float64[], NMI=Float64[], AMI=Float64[], RI=Float64[], ARI=Float64[],\n",
    "              GRI=Float64[], AGRI=Float64[])\n",
    "n = length(gt)\n",
    "tc = Dict(zip(0:n-1, gt))\n",
    "ar = 2:20\n",
    "for s in ar\n",
    "    for i in 1:100\n",
    "        r = rand(1:s, n)\n",
    "        rc = Dict(zip(0:n-1,r))\n",
    "        push!(D, (s, MI(gt, r), NMI(gt, r), AMI(gt, r), RI(gt, r), ARI(gt, r),\n",
    "                  gp.gam(tc, rc, adjusted=false), gp.gam(tc, rc)))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = combine(groupby(D, :size), names(D, Not(:size)) .=> mean, renamecols=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ar, R.MI,\":\",color=\"black\",label=\"MI\")\n",
    "plot(ar, R.NMI,\"--\",color=\"black\",label=\"NMI\")\n",
    "plot(ar, R.AMI,\"-\",color=\"black\",label=\"AMI\")\n",
    "xlabel(\"number of random clusters\",fontsize=14)\n",
    "legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ar, R.RI,\":\",color=\"black\",label=\"RI\")\n",
    "plot(ar, R.GRI,\"--\",color=\"black\",label=\"GRI\")\n",
    "plot(ar, R.ARI,\"-\",color=\"black\",label=\"ARI/AGRI\")\n",
    "plot(ar, R.ARI,\"-\",color=\"black\")\n",
    "xlabel(\"number of random clusters\",fontsize=14)\n",
    "legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
